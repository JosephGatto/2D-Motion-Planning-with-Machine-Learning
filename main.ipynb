{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from synthesize.synthesize import placeRandomRooms, synthesize_train_set, synthetic_sensor\n",
    "from utils.planning import  get_path, plot_path\n",
    "from utils.processing import create_classification_problem\n",
    "from utils.plotting import plot_path_with_lines\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "import random\n",
    "from copy import deepcopy\n",
    "import math\n",
    "from shapely.geometry import LineString\n",
    "from astar.gridmap import OccupancyGridMap\n",
    "import argparse\n",
    "from shapely.geometry import MultiLineString, LineString\n",
    "from copy import deepcopy\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    robot_type = 'omni'\n",
    "    map_size = (50,50)\n",
    "    num_train_maps = 10\n",
    "    num_train_paths = 100\n",
    "    use_polar = True \n",
    "    num_sensor_readings = 4\n",
    "    movement = '4N'\n",
    "    dirs = {0:(1.0, 0.0), 1:(0.0, 1.0), 2:(-1.0, 0.0), 3:(0.0, -1.0)}\n",
    "    inv_dirs = {d: label for label, d in dirs.items()}\n",
    "    enc = preprocessing.LabelEncoder()\n",
    "    steer = {0:0, 1:np.pi/2., -1:-np.pi/2, 2:np.pi, -2:np.pi, 3:-np.pi/2, -3:np.pi/2}\n",
    "    img_root = 'gifs'\n",
    "    \n",
    "args=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(MAP, map_np, start, goal, model, args):\n",
    "    \n",
    "    groud_truth = get_path(start, goal, map_np, plot=True) \n",
    "    print(\"Number of steps taken in A* Path, \", len(groud_truth))\n",
    "    pred_path = [start]\n",
    "    cur_dir = (0, 0)\n",
    "    cur = start\n",
    "    directions = []\n",
    "    while cur != goal:\n",
    "\n",
    "        laser_scan, lines = synthetic_sensor(MAP, (cur[0]+0.5, cur[1]+0.5), direction=cur_dir, args = args)\n",
    "        offset = 0\n",
    "        if cur_dir != (0, 0): # Start node\n",
    "            offset = args.inv_dirs[cur_dir]\n",
    "        rot = np.pi/2 * offset \n",
    "        goal_loc = (goal[0]-cur[0], goal[1]-cur[1])  \n",
    "        goal_orn = (goal_loc[0]*np.cos(rot) + goal_loc[1]*np.sin(rot), goal_loc[0]*-np.sin(rot) + goal_loc[1]*np.cos(rot))\n",
    "        if args.robot_type == 'omni':\n",
    "            laser_scan.append(goal_loc[0])\n",
    "            laser_scan.append(goal_loc[1])\n",
    "        elif args.robot_type == 'ddr':\n",
    "            if args.use_polar:\n",
    "                polar_distance = np.linalg.norm(np.array([goal_loc[0],goal_loc[1]]))\n",
    "                polar_rotation = math.atan2(goal_orn[1], goal_orn[0])\n",
    "                laser_scan.append(polar_distance)\n",
    "                laser_scan.append(polar_rotation)\n",
    "            else:\n",
    "                laser_scan.append(goal_orn[0])\n",
    "                laser_scan.append(goal_orn[1])\n",
    "\n",
    "        # Create model input\n",
    "        inpX = np.array(laser_scan)\n",
    "        inds = model.predict_proba(inpX.reshape(1,-1))[0]\n",
    "        best = list(np.argsort(inds))  \n",
    "        best.reverse()\n",
    "\n",
    "        possible_dirs = [eval(args.enc.inverse_transform(best)[ii]) for ii in range(len(best))]\n",
    "        if args.robot_type == 'omni':\n",
    "            possible_next_states = [(cur[0] + d[0], cur[1] + d[1]) for d in possible_dirs]\n",
    "        elif args.robot_type == 'ddr':\n",
    "            possible_steers = [(np.cos(rot + args.steer[ind]), np.sin(rot + args.steer[ind])) for ind in possible_dirs]\n",
    "            possible_next_states = [(cur[0] + steers[0], cur[1] + steers[1]) for steers in possible_steers]\n",
    "\n",
    "        temp_states = deepcopy(possible_next_states)\n",
    "        for state in possible_next_states:\n",
    "            if (state in pred_path):\n",
    "                temp_states.remove(state) \n",
    "\n",
    "        directions.append(cur_dir)\n",
    "        cur_dir = (temp_states[0][0] - cur[0], temp_states[0][1] - cur[1])\n",
    "        cur = temp_states[0]\n",
    "\n",
    "        assert cur not in pred_path\n",
    "        pred_path.append(cur)\n",
    "        if cur == goal:\n",
    "            temp = [(p[0]+0.5, p[1]+0.5) for p in pred_path]\n",
    "            if LineString(temp).intersects(MAP):\n",
    "                success = 0\n",
    "            else:\n",
    "                success = 1\n",
    "            break\n",
    " \n",
    "    return pred_path, directions, success, groud_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:16<00:00,  6.24it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAPS = []\n",
    "\n",
    "for i in range(args.num_train_maps):\n",
    "    train_arr, train_MAP = placeRandomRooms(args.map_size, minRoomSize=3, maxRoomSize=15, roomStep = 1, margin = 4, attempts = 100)\n",
    "    MAPS.append((train_MAP,train_arr))\n",
    "\n",
    "df_ = synthesize_train_set(MAPS, args)\n",
    "df = create_classification_problem(df_.copy(), args)\n",
    "\n",
    "# Fit model using all data.\n",
    "clf = RandomForestClassifier(n_estimators=200)\n",
    "clf.fit(df.drop(['out'], axis=1).values, df['out'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of steps taken in A* Path,  21\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of steps taken in pred Path 21\n",
      "Safe path found!\n"
     ]
    }
   ],
   "source": [
    "pred_len = []\n",
    "astar_len = []\n",
    "n_test = 0\n",
    "successes = 0\n",
    "avgs = []\n",
    "while n_test < 1:\n",
    "\n",
    "    min_node, max_node = 1, args.map_size[1]-1\n",
    "    start = (random.randint(min_node, max_node), random.randint(min_node, max_node))\n",
    "    goal = (random.randint(min_node, max_node), random.randint(min_node, max_node))\n",
    "    arr, test_MAP = placeRandomRooms(args.map_size, minRoomSize=3, maxRoomSize=15, roomStep = 1, margin = 4, attempts = 100)\n",
    "    try:\n",
    "        pred_path, directions, success, ground_truth = test_model(test_MAP, arr, start, goal, clf, args)\n",
    "        OccupancyGridMap(arr, 1).plot()\n",
    "        plot_path(pred_path)\n",
    "        pred_len.append(len(pred_path))\n",
    "        print('Number of steps taken in pred Path', len(pred_path))\n",
    "        astar_len.append(len(get_path(start, goal, arr, False)))\n",
    "        if success == 1:\n",
    "            print(\"Safe path found!\")\n",
    "            avgs.append(len(pred_path)- len(ground_truth) )\n",
    "        else:\n",
    "            print(\"Invalid path computed :(\")\n",
    "        break\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "plot_path_with_lines(pred_path[:-1], test_MAP, directions, args)\n",
    "Image(args.img_root+'/out.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
