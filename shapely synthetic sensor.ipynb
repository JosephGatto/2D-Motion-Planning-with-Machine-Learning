{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shapely\n",
    "from shapely.geometry import box, MultiPolygon, LineString, Point, MultiLineString, Polygon\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "from gridmap import OccupancyGridMap\n",
    "import matplotlib.pyplot as plt\n",
    "from a_star import a_star\n",
    "from utils import plot_path\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import imageio\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points_on_circ = 360\n",
    "pi = math.pi\n",
    "def PointsInCircum(r,n=num_points_on_circ, center = (0,0)):\n",
    "    return np.array([(center[0] + math.cos(2*pi/n*x)*r, center[1] + math.sin(2*pi/n*x)*r) for x in range(0,n+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_shapely_map(map_size, obstacles):\n",
    "    '''\n",
    "    Given map_size and list of obstacles where\n",
    "    an obstacle is described by a tuple (xmin, ymin, xmax, ymax),\n",
    "    create a shapely map. \n",
    "    '''\n",
    "    \n",
    "    pols = [box(0,0,map_size[0], map_size[1])]\n",
    "    for obstacle in obstacles:\n",
    "        pols.append(box(*obstacle))\n",
    "    lines = []\n",
    "    for pol in pols:\n",
    "        boundary = pol.boundary\n",
    "        if boundary.type == 'MultiLineString':\n",
    "            for line in boundary:\n",
    "                lines.append(line)\n",
    "        else:\n",
    "            lines.append(boundary)\n",
    "\n",
    "    MAP = MultiLineString(lines)\n",
    "    return MAP\n",
    "\n",
    "def get_map_arr(MAP_params, shape):\n",
    "    '''\n",
    "    Convert the shapely obstacles into a numpy grid\n",
    "    for use with the A* planner. \n",
    "    \n",
    "    MAP_params is of the form [(xmin, ymin, xmax, ymax), (xmin, ymin, xmax, ymax), ...]\n",
    "    describing each rectangular obstacle in the map. Currently only supports rectangles. \n",
    "    \n",
    "    Shape is just a tuple with the map size. \n",
    "    \n",
    "    '''\n",
    "    map_np = np.zeros(shape)\n",
    "    for param in MAP_params:\n",
    "        xmin, ymin, xmax, ymax = param\n",
    "        map_np[ymin:ymax, xmin:xmax] = 1\n",
    "        \n",
    "    return map_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthetic_sensor(MAP, robot_location):\n",
    "    '''\n",
    "    Given a shapely map and the robots current location, \n",
    "    return the 360 degree laser scanner. \n",
    "    '''\n",
    "    lines = []\n",
    "    # 100 is arbitrary radius. Just needs to be big enough to draw line across map. \n",
    "    points = PointsInCircum(100, center = robot_location)\n",
    "    # Create line to all points on circle\n",
    "    for point in points:\n",
    "        A = Point(robot_location)\n",
    "        B = Point(point)\n",
    "        line = LineString([A,B])\n",
    "        lines.append(line)\n",
    "        \n",
    "    # Get points of intersection. \n",
    "    for i, line in enumerate(lines):\n",
    "\n",
    "        # These two types of objects signify multiple intersections. \n",
    "        if type(MAP.intersection(line)) == shapely.geometry.multilinestring.MultiLineString or \\\n",
    "               type(MAP.intersection(line)) == shapely.geometry.multipoint.MultiPoint:\n",
    "            # Get the closest point\n",
    "            temp_dist = []\n",
    "            for point in MAP.intersection(line):\n",
    "#                 try:\n",
    "                temp_dist.append(LineString([robot_location, point]).length)\n",
    "            inter = MAP.intersection(line)[np.argmin(temp_dist)]\n",
    "        # This signifies no intersection. Wont happen on current map. \n",
    "        elif type(MAP.intersection(line)) == shapely.geometry.collection.GeometryCollection:\n",
    "            cp = MAP.intersection(line)[0] \n",
    "            lines[i].coords = [robot_location, cp]\n",
    "            continue\n",
    "        # One intersection\n",
    "        else:\n",
    "            inter = MAP.intersection(line)\n",
    "        # Create new point and update end point in list of lines. \n",
    "        new_point = (inter.xy[0][0], inter.xy[1][0])\n",
    "        lines[i].coords = [robot_location, new_point]\n",
    "    \n",
    "    # Get lase scan data (distances)\n",
    "    distances = [line.length for line in lines]\n",
    "    return distances[:num_points_on_circ], lines\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(MAP, robot_location, line_strings = None, plot_lines=False):\n",
    "    '''\n",
    "    This plot function is used to show the laser scan lines. \n",
    "    Current not used. Probably will be helpful when creating visualizations. \n",
    "    '''\n",
    "    fig = plt.figure(frameon=False)\n",
    "    fig.set_size_inches(50,50)\n",
    "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "    ax.set_axis_off()\n",
    "    fig.add_axes(ax)\n",
    "    for index, l in enumerate(MAP): \n",
    "        if index != 0:\n",
    "            ax.fill(*l.xy, alpha=1)\n",
    "        else:\n",
    "            ax.plot(*l.xy, alpha=1)\n",
    "    if plot_lines:\n",
    "        for line in line_strings:\n",
    "            ax.plot(*line.xy, alpha=0.25)\n",
    "    ax.scatter(*robot_location, s=30, alpha=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path(start, goal, arr, plot = True):\n",
    "    '''\n",
    "    Given start (x,y) and goal (x,y) use numpy grid arr\n",
    "    to solve for best path with A*. \n",
    "    \n",
    "    By default, plot the A* path everytime this is called. \n",
    "    '''\n",
    "    resolution = 1\n",
    "    gmap = OccupancyGridMap(arr, resolution)\n",
    "\n",
    "    # 4n = 4 point connectivity. 8N = 8 point connectivity\n",
    "    path, path_px = a_star(start, goal, gmap, movement='4N')\n",
    "    if plot:\n",
    "        gmap.plot()\n",
    "        plot_path(path_px)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_path_(MAP, robot_location, goal_location, path):\n",
    "    '''\n",
    "    Plot path on map using shapely. Not currently used. \n",
    "    '''\n",
    "    fig = plt.figure(frameon=False)\n",
    "    fig.set_size_inches(6,6)\n",
    "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "    fig.add_axes(ax)\n",
    "    \n",
    "    for index, l in enumerate(MAP): \n",
    "        if index != 0:\n",
    "            ax.fill(*l.xy, alpha=1)\n",
    "        else:\n",
    "            ax.plot(*l.xy, alpha=1)\n",
    "    \n",
    "    ax.plot(*LineString(path).xy)\n",
    "    ax.scatter(robot_location[0], robot_location[1], s=30, alpha=1.0) \n",
    "    ax.scatter(goal_location[0], goal_location[1], s=30, alpha=1.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesize_data(start, goal, MAP, map_arr):\n",
    "    '''\n",
    "    synthesize data for one step. \n",
    "    \n",
    "    -Given start and goal, we first get the A* ground truth path. \n",
    "    -If get_path() returns an error, that means there was no path found. \n",
    "    -For each element in the path, use the synthetic sensor to get the readings \n",
    "        the relative goal in odom, and the target movement\n",
    "    '''\n",
    "    \n",
    "    # Get path if one is available\n",
    "    try:\n",
    "        path = get_path(start, goal, map_arr, False)\n",
    "    except:\n",
    "        return\n",
    "    \n",
    "    sensor_readings = []\n",
    "    relative_goals = []\n",
    "    directions = []\n",
    "    prev = start\n",
    "    for i, loc in enumerate(path):\n",
    "        # Get laser scan\n",
    "        ls,_ = synthetic_sensor(MAP, (loc[0]+0.5, loc[1]+0.5))\n",
    "        sensor_readings.append(ls)\n",
    "        # Get goal in odom\n",
    "        relative_goals.append((goal[0]-loc[0], goal[1]-loc[1]))\n",
    "        # Get movement to next cell\n",
    "        directions.append((loc[0] - prev[0], loc[1] - prev[1]))\n",
    "        prev=loc\n",
    "    return np.array(sensor_readings), np.array(relative_goals), directions, path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesize_train_set(MAPs, num_runs = 5):\n",
    "    '''\n",
    "    -Get 'num_runs' different start/goal locations inside the map\n",
    "    -If path is available, get training data for a given path\n",
    "    -Return pandas dataframe where first 360 columns are sensor data, cols\n",
    "     361 and 362 are odom info and then last 2 columns are x,y movement directions. \n",
    "    '''\n",
    "    \n",
    "    df = []\n",
    "    \n",
    "    for i in tqdm(range(num_runs)):\n",
    "        # TODO: Generalize to any map shape\n",
    "        start = (random.randint(1,49), random.randint(1,49))\n",
    "        goal = (random.randint(1,49), random.randint(1,49))\n",
    "        MAP, map_arr = random.choice(MAPs)\n",
    "        # If path is available, get training info\n",
    "        try:\n",
    "            (sensor_readings, relative_goals, directions, path) = synthesize_data(start, goal, MAP, map_arr)\n",
    "            train = np.concatenate((sensor_readings, relative_goals, directions), axis=1)\n",
    "            df.append(train)\n",
    "        except:\n",
    "            # No path found\n",
    "            continue\n",
    "    return pd.DataFrame(np.vstack(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tuple(x):\n",
    "    '''\n",
    "    Function used to turn 2 pandas columns into\n",
    "    a tuple in one column. See create_classification_problem\n",
    "    for use. \n",
    "    '''\n",
    "    return (x.iloc[0], x.iloc[1])\n",
    "\n",
    "def create_classification_problem(df, one_hot = False):\n",
    "    '''\n",
    "    Now that training data has been synthesized, \n",
    "    prepare data for use with ML model. \n",
    "    '''\n",
    "    \n",
    "    # Turn (x,y) target into into string tuple\n",
    "    # so we can then use label encoding to turn\n",
    "    # this into a classification problem. \n",
    "    df['out'] = df[[num_points_on_circ+2,num_points_on_circ+3]].apply(make_tuple, axis=1)\n",
    "    df['out'] = df['out'].astype(str)\n",
    "    \n",
    "    # Drop the sample where we are at the target location. \n",
    "    # We don't want to learn to stay still. \n",
    "    df = df[df['out']!='(0.0, 0.0)']\n",
    " \n",
    "    # Label encode targets\n",
    "    enc = preprocessing.LabelEncoder()\n",
    "    df['out'] = enc.fit_transform(df['out'])\n",
    "    \n",
    "    # Added one-hot encoding option which\n",
    "    # may be neccessary for some models\n",
    "    if one_hot:\n",
    "        ohe = preprocessing.OneHotEncoder(sparse=False)\n",
    "        ohe.fit(df['out'].values.reshape(-1,1)) \n",
    "        df['out'] = df['out'].apply(lambda x : ohe.transform(x))\n",
    "        df['out'] = df['out'].apply(lambda x : x[0])\n",
    "    \n",
    "    # Drop the (x,y) target columns, which have now\n",
    "    # been label encoded. \n",
    "    df.drop([num_points_on_circ+2, num_points_on_circ+3], axis=1, inplace=True)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a745714b48>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Map obstacles for training map. \n",
    "map_params = [(10, 10, 12, 16), (35,35,48,37), (0,5,8,8), (20,20,25,25), (40,11,49,4), (2,45,14,48), (44,0,49,20), (20,30,25,39)]\n",
    "map_size = (50,50)\n",
    "# Gen training map\n",
    "train_MAP1 = gen_shapely_map(map_size, map_params)\n",
    "# Convert to numpy array for A*\n",
    "arr1 = get_map_arr(map_params, map_size)\n",
    "plt.imshow(arr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a7456f18c8>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Map obstacles for training map. \n",
    "map_params = [(1,1,10,10),(10,15,20,20), (40,40,45,45),(30,30,40,40), (0,40,15,41)]\n",
    "map_size = (50,50)\n",
    "# Gen training map\n",
    "train_MAP2 = gen_shapely_map(map_size, map_params)\n",
    "# Convert to numpy array for A*\n",
    "arr2 = get_map_arr(map_params, map_size)\n",
    "plt.imshow(arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a745809d08>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Map obstacles for training map. \n",
    "map_params = [(10,5,13,20),(40,0,42,20), (1,49,22,50), (30,30,40,40), (20,20,30,30)]\n",
    "map_size = (50,50)\n",
    "# Gen training map\n",
    "train_MAP3 = gen_shapely_map(map_size, map_params)\n",
    "# Convert to numpy array for A*\n",
    "arr3 = get_map_arr(map_params, map_size)\n",
    "plt.imshow(arr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a7458cc508>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Map obstacles for training map. \n",
    "map_params = [(1,4,20,20), (0,45,10,49), (40,40,49,49), (45,5,49,20), (15,15,20,28), (30,40,33,44), (30,10,39,19), (15,35,20,40), (30,30,35,35), (0,30,5,35)]\n",
    "map_size = (50,50)\n",
    "# Gen training map\n",
    "train_MAP4 = gen_shapely_map(map_size, map_params)\n",
    "# Convert to numpy array for A*\n",
    "arr4 = get_map_arr(map_params, map_size)\n",
    "plt.imshow(arr4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPS = [(train_MAP1, arr1), (train_MAP2,arr2), (train_MAP3, arr3), (train_MAP4, arr4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create training data\n",
    "# df_ = synthesize_train_set(MAPS)\n",
    "# # Prep data for modeling\n",
    "# df = create_classification_problem(df_.copy()) \n",
    "# # Shuffle data (otherwise model can cheat and memorize order since these are no iid)\n",
    "# df = df.sample(frac=1)\n",
    "df = pd.read_csv('500_multimap2.csv')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=36, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=150,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(cross_val_score(RandomForestClassifier(), df.drop(['out'], axis=1).values, df['out'].values, cv=3, scoring = 'f1_micro'))\n",
    "# Fit model using all data.\n",
    "clf = RandomForestClassifier(n_estimators=150, max_depth=36)\n",
    "df.drop(0, axis=0, inplace=True)\n",
    "clf.fit(df.drop(['out'], axis=1).values, df['out'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "'''\n",
    "Testing Env:\n",
    "\n",
    "Now we use trained model to nav unseen map. \n",
    "'''\n",
    "\n",
    "# Mapping from label encoder (just hard coded it here)\n",
    "dirs = {0:(-1.0, 0.0), 1:(0.0, -1.0), 2:(0.0, 1.0), 3:(1.0, 0.0)}\n",
    "\n",
    "\n",
    "map_params = [(5,8,18,23), (45,0,50,12), (10,10,15,15), (25,20,35,25), (44,44,49,49), (31,38,40,40), (30,10,39,19), (15,25,28,30), (30,30,35,35),(0,45,10,46), (20,30,5,35)]\n",
    "map_size = (50,50)\n",
    "# Gen training map\n",
    "test_MAP = gen_shapely_map(map_size, map_params)\n",
    "# Convert to numpy array for A*\n",
    "arr = get_map_arr(map_params, map_size)\n",
    "\n",
    "def test_on_new_map(_MAP, test_arr, start, goal, model):\n",
    "    \n",
    "    '''\n",
    "    Test model performance on unseen map. \n",
    "    \n",
    "    test_MAP = shapely map\n",
    "    test_arr = numpy grid of mapll\n",
    "    \n",
    "    start,goal = (x,y), (x,y)\n",
    "    model = trained sklearn model \n",
    "    '''\n",
    "    \n",
    "    # Get ground-truth path\n",
    "    groud_truth = get_path(start, goal, test_arr) \n",
    "    print(\"Number of steps taken in A* Path, \", len(groud_truth))\n",
    "    \n",
    "    # i counter just helps stop after a certain number of steps since\n",
    "    # at the moment the algorithm probably wont reach the goal. \n",
    "    i=0\n",
    "    # Start saving the path traveled\n",
    "    pred_path = [start]\n",
    "    \n",
    "    cur = start\n",
    "    while cur != goal:\n",
    "        try:\n",
    "            # Get the laser_scan data for the current point\n",
    "#             cur = (cur[0]+1, cur[1]+1)\n",
    "            laser_scan, lines = synthetic_sensor(_MAP, (cur[0]+0.5, cur[1]+0.5))\n",
    "            laser_scan.append(goal[0]-cur[0])\n",
    "            laser_scan.append(goal[1]-cur[1])\n",
    "            # Create model input\n",
    "            inpX = np.array(laser_scan)\n",
    "            # Get predicted direction\n",
    "            inds = clf.predict_proba(inpX.reshape(1,-1))[0]\n",
    "            best = list(np.argsort(inds))\n",
    "            best.reverse()\n",
    "\n",
    "            possible_next_states = [(cur[0] + dirs[ind][0], cur[1] + dirs[ind][1]) for ind in best]\n",
    "            temp_states = deepcopy(possible_next_states)\n",
    "            for state in possible_next_states:\n",
    "                if (-1 in state) or (50 in state) or (0 in state) or (state in pred_path):\n",
    "                    temp_states.remove(state)\n",
    "\n",
    "            # Update state\n",
    "            cur = temp_states[0]\n",
    "            assert cur not in pred_path\n",
    "            pred_path.append(cur)\n",
    "            # Cout number of steps traveled \n",
    "            i+=1\n",
    "            if i==100 or cur == goal:\n",
    "                break\n",
    "        except:\n",
    "            break\n",
    "    \n",
    "    return pred_path \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAMfUlEQVR4nO3dXYxc9XnH8e8Tv20cFBsSsBwMhRJXgliJUVauJXoBdiQoJMFSiZSXtr6w5JtUIgUpJa3UKlUvwg3kpjdWjGI1UYCSSCCEhNDGVtQbEzsQarJqbCPVdbHspGBIatlg++nFHFd+2WVn5332+X6k0cz5zzl7frL25//M2TlnIjORtPB9aNgBJA2GZZeKsOxSEZZdKsKyS0UsHuTOlsaynOAjg9ylVMpp/pf38kzM9NxAyz7BR/jj2DzIXUql7M2pWZ/zZbxUhGWXihjoy3ipshfffLUvP/fuT6xvaz1ndqkIyy4VYdmlIiy7VIRll4qw7FIRll0qwrJLRVh2qQjLLhVh2aUiLLtUxEBPhPmjT5/ixRf7czJAP7R7goE0DpzZpSIsu1SEZZeKsOxSEQM9QPfr15Z70EsaEmd2qQjLLhVh2aUivLqsNCDDPl7lzC4VYdmlIiy7VIRll4qw7FIRll0qwrJLRVh2qQjLLhVh2aUiLLtUhGWXimi77BGxKCJeiYjnm+WbI2JvRByMiKciYmn/Ykrq1nxm9geB6YuWHwUez8y1wNvAtl4Gk9RbbZU9ItYA9wHfa5YD2AQ806yyC9jSj4CSeqPdmf27wDeB883yx4CTmXm2WT4KXD/ThhGxPSL2RcS+9znTVVhJnZuz7BHxeeBEZu6/eHiGVXOm7TNzR2ZOZubkEpZ1GFNSt9q5Us0dwBcj4l5gAvgorZl+ZUQsbmb3NcCb/Yuphe7FN0f3a8GGfYWZXplzZs/Mb2Xmmsy8Cfgy8NPM/BqwG3igWW0r8GzfUkrqWjd/Z/8b4KGIOETrPfzO3kSS1A/zuuBkZu4B9jSP3wA29D6SpH7wE3RSEZZdKsKyS0VYdqkIvxFGI2Gh/C17lDmzS0VYdqkIyy4VYdmlIiy7VIRll4qw7FIRll0qwrJLRVh2qQjLLhVh2aUiPBFGQ9GvC0x6Qs3snNmlIiy7VIRll4qw7FIRll0qwrJLRVh2qQjLLhVh2aUiLLtUhGWXirDsUhGWXSrCsktFWHapCMsuFTFn2SNiIiJejohfRsTrEfHtZvzmiNgbEQcj4qmIWNr/uJI61c7MfgbYlJmfAdYD90TERuBR4PHMXAu8DWzrX0xJ3Zqz7Nny+2ZxSXNLYBPwTDO+C9jSl4SSeqKt9+wRsSgiXgVOAC8Bh4GTmXm2WeUocP0s226PiH0Rse99zvQis6QOtFX2zDyXmeuBNcAG4NaZVptl2x2ZOZmZk0tY1nlSSV2Z19VlM/NkROwBNgIrI2JxM7uvAd7sQ74Fp19XVR0l7Vzh1avADl47R+OvjYiVzeMPA58DpoHdwAPNaluBZ/sVUlL32pnZVwO7ImIRrf8cns7M5yPiV8CTEfFPwCvAzj7mlNSlOcuema8Bt88w/gat9++SxoCfoJOKsOxSEZZdKsKyS0VYdqkIyy4VYdmlIiy7VIRll4qw7FIRll0qwrJLRVh2qYh5XbxC0nAdW3eEw5sPcHrFKSbeWc4tU+tYfeDGtra17NKYOLbuCNNf2M/5pecAOL3yFNNf2A/QVuEtuxaU2+97g09tPjLsGH3x8LtvcT7PXzJ2fuk5Dm8+0FbZfc+uBeVTm4+w6pPvDDtGX/zPZUW/4PSKU21t78yuBef4oRX84KE7hx2j5yYefIHTK68s9sQ7y9va3rIP2LhdVbWTq+EO8wq6//Lk0Hbdd7dMrbvkPTvAh95bxC1T69ra3rJLY+LC+3KPxksFrD5wY9vlvpwH6KQiLLtUhGWXirDsUhGWXSrCsktFLIg/vS30r0Eetw/iaDQ5s0tFWHapCMsuFWHZpSIsu1SEZZeKmLPsEXFDROyOiOmIeD0iHmzGr4mIlyLiYHN/df/jSupUOzP7WeDhzLwV2Ah8PSJuAx4BpjJzLTDVLEsaUXOWPTOPZeYvmse/A6aB64H7gV3NaruALf0KKal783rPHhE3AbcDe4FVmXkMWv8hANf1Opyk3mm77BFxFfBj4BuZ+e48ttseEfsiYt/7nOkko6QeaKvsEbGEVtF/mJk/aYaPR8Tq5vnVwImZts3MHZk5mZmTS1jWi8ySOjDniTAREcBOYDozH7voqeeArcB3mvtn+5JQQzVuJ+H8+WN7hh1hZLVz1tsdwF8A/x4RF04v+1taJX86IrYBR4Av9Seihm2cvmVl1Sff4fihFcOOMZLmLHtm/hsQszy9ubdxNIoufMvKOJTo+KEVvD7V2dVXF7oFcT67+m+hfstKJZZdQzHKFxwZt+MU7fKz8VIRll0qwrJLRVh2qQjLLhVh2aUiLLtUhGWXirDsUhGWXSrCsktFWHapCMsuFWHZpSIsu1SEZZeKsOxSEZZdKsKyS0VYdqkIyy4VYdmlIiy7VIRll4qw7FIRll0qwrJLRVh2qQjLLhVh2aUi/MpmaUj68bXVG+4+NetzzuxSEZZdKmLOskfEExFxIiIOXDR2TUS8FBEHm/ur+xtTw3JXHuHP/vEt/vKvf8sP8gXuyiPDjqQOtTOzfx+457KxR4CpzFwLTDXLWmDuyiM8xH6uevs8AaziFA+x38KPqTnLnpk/A966bPh+YFfzeBewpce5NAK2cYAJzl0yNsE5tnFgli00yjp9z74qM48BNPfXzbZiRGyPiH0Rse99znS4Ow3Dtcx8ZHe2cY22vh+gy8wdmTmZmZNLWNbv3amHfsPyeY1rtHX6d/bjEbE6M49FxGrgRC9DaTTsZB0Psf+Sl/KnWcRO1nX9s+/+xPquf4bmp9OZ/Tlga/N4K/Bsb+JolOyOG3mMz3Kc5ZwHjrOcx/gsu+PGYUdTB+ac2SPiR8CdwMcj4ijwD8B3gKcjYhtwBPhSP0NqeHbHjezGci8Ec5Y9M78yy1Obe5xFUh/5CTqpCMsuFWHZpSIsu1SEZZeKWBAXr/ADGtLcnNmlIiy7VIRll4qw7FIRll0qwrJLRVh2qQjLLhVh2aUiLLtUhGWXirDsUhGWXSrCsktFWHapCMsuFWHZpSIsu1SEZZeKsOxSEZZdKsKyS0VYdqkIyy4VYdmlIiy7VIRll4qw7FIRXZU9Iu6JiP+IiEMR8UivQknqvY7LHhGLgH8G/hS4DfhKRNzWq2CSequbmX0DcCgz38jM94Angft7E0tSr3VT9uuB/7po+WgzJmkELe5i25hhLK9YKWI7sB1gguVd7E5SN7qZ2Y8CN1y0vAZ48/KVMnNHZk5m5uQSlnWxO0ndiMwrJuP2NoxYDPwa2Az8N/Bz4KuZ+foHbPMb4D+BjwO/7WjHgzdOWWG88o5TVhiPvH+QmdfO9ETHL+Mz82xE/BXwIrAIeOKDit5scy1AROzLzMlO9z1I45QVxivvOGWF8ct7uW7es5OZLwAv9CiLpD7yE3RSEcMq+44h7bcT45QVxivvOGWF8ct7iY4P0EkaL76Ml4qw7FIRAy37qJ8lFxFPRMSJiDhw0dg1EfFSRBxs7q8eZsYLIuKGiNgdEdMR8XpEPNiMj2reiYh4OSJ+2eT9djN+c0TsbfI+FRFLh531gohYFBGvRMTzzfLIZm3HwMo+JmfJfR+457KxR4CpzFwLTDXLo+As8HBm3gpsBL7e/HuOat4zwKbM/AywHrgnIjYCjwKPN3nfBrYNMePlHgSmL1oe5axzGuTMPvJnyWXmz4C3Lhu+H9jVPN4FbBloqFlk5rHM/EXz+He0fimvZ3TzZmb+vllc0twS2AQ804yPTN6IWAPcB3yvWQ5GNGu7Bln2cT1LblVmHoNWwYDrhpznChFxE3A7sJcRztu8LH4VOAG8BBwGTmbm2WaVUfqd+C7wTeB8s/wxRjdrWwZZ9rbOktP8RMRVwI+Bb2Tmu8PO80Ey81xmrqd10tQG4NaZVhtsqitFxOeBE5m5/+LhGVYdetb56OrjsvPU1llyI+h4RKzOzGMRsZrWrDQSImIJraL/MDN/0gyPbN4LMvNkROyhdaxhZUQsbmbMUfmduAP4YkTcC0wAH6U1049i1rYNcmb/ObC2OaK5FPgy8NwA99+p54CtzeOtwLNDzPL/mveQO4HpzHzsoqdGNe+1EbGyefxh4HO0jjPsBh5oVhuJvJn5rcxck5k30fo9/Wlmfo0RzDovmTmwG3AvrdNiDwN/N8h9t5nvR8Ax4H1ar0S20XqvNgUcbO6vGXbOJuuf0HoZ+RrwanO7d4Tzfhp4pcl7APj7ZvwPgZeBQ8C/AsuGnfWy3HcCz49D1rluflxWKsJP0ElFWHapCMsuFWHZpSIsu1SEZZeKsOxSEf8HPK2to4cvAw4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of steps taken in A* Path,  39\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "start = (25,10)\n",
    "goal = (48,25)\n",
    "pred_path = test_on_new_map(test_MAP, arr, start, goal, clf)\n",
    "OccupancyGridMap(arr, 1).plot()\n",
    "plot_path(pred_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_path_with_lines(pred_path, MAP):\n",
    "    '''\n",
    "    Given predicted path nodes and map, \n",
    "    plot the path and the sensor readings for each node\n",
    "    '''\n",
    "    # Update node positions for shapely plotting\n",
    "    pred_path = [(p[0]+0.5, p[1]+0.5) for p in pred_path]\n",
    "    # Save filenames for GIF creation\n",
    "    filenames=[]\n",
    "    for i, node in enumerate(pred_path):\n",
    "        # Create fig\n",
    "        fig = plt.figure(frameon=False)\n",
    "        fig.set_size_inches(6,6)\n",
    "        plt.plot(*LineString(pred_path).xy)\n",
    "        plt.scatter(*node, s=30, alpha=1.0)\n",
    "        # Get lines from sensor \n",
    "        _, lines = synthetic_sensor(MAP, node)\n",
    "        for index, l in enumerate(MAP): \n",
    "            if index != 0:\n",
    "                plt.fill(*l.xy, alpha=1)\n",
    "            else:\n",
    "                plt.plot(*l.xy, alpha=1)\n",
    "        for k, line in enumerate(lines):\n",
    "            plt.plot(*line.xy, alpha=0.25)\n",
    "        filenames.append('img_{}.png'.format(i))\n",
    "        plt.savefig('img_{}.png'.format(i))\n",
    "        plt.close()\n",
    "    \n",
    "    # Make GIF\n",
    "    images = []\n",
    "    for filename in filenames:\n",
    "        images.append(imageio.imread(filename))\n",
    "    imageio.mimsave('demo.gif', images)\n",
    "        \n",
    "plot_path_with_lines(pred_path, test_MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-244-4d33aa6676c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotebook\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "# DL Solution ... not currently learning. \n",
    "\n",
    "import torch\n",
    "class SensorData(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df.copy()\n",
    "        self.mms = MinMaxScaler()\n",
    "        self.mms.fit(df.drop('out', axis=1).values)\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.df.iloc[idx]\n",
    "        x = self.mms.transform(sample.drop('out').values.astype(np.float32).reshape(1,-1))\n",
    "        y = sample['out']\n",
    "        return (torch.from_numpy(x).double(), y)\n",
    "    \n",
    "ds = SensorData(df)\n",
    "train_loader = torch.utils.data.DataLoader(ds,64,True, num_workers=0, pin_memory=True)\n",
    "\n",
    "from resnet1d import ResNet1D\n",
    "model = ResNet1D(1,64,3,3,1,24,4).cuda()\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "\n",
    "loss = 0\n",
    "for i in range(20):\n",
    "    ep_loss = 0\n",
    "    for batch in tqdm(train_loader):\n",
    "        model.train()\n",
    "        x,y = batch[0].cuda().float(), batch[1].cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out = model(x)\n",
    "        loss = criterion(out,y.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        ep_loss += loss.item()\n",
    "        \n",
    "    print(ep_loss/len(train_loader))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
