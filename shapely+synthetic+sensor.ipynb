{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joega\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import shapely\n",
    "from shapely.geometry import box, MultiPolygon, LineString, Point, MultiLineString, Polygon\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "from gridmap import OccupancyGridMap\n",
    "import matplotlib.pyplot as plt\n",
    "from a_star import a_star\n",
    "from utils import plot_path\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pi = math.pi\n",
    "def PointsInCircum(r,n=360, center = (0,0)):\n",
    "    return np.array([(center[0] + math.cos(2*pi/n*x)*r, center[1] + math.sin(2*pi/n*x)*r) for x in range(0,n+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_shapely_map(map_size, obstacles):\n",
    "    '''\n",
    "    Given map_size and list of obstacles where\n",
    "    an obstacle is described by a tuple (xmin, ymin, xmax, ymax),\n",
    "    create a shapely map. \n",
    "    '''\n",
    "    \n",
    "    pols = [box(0,0,map_size[0], map_size[1])]\n",
    "    for obstacle in obstacles:\n",
    "        pols.append(box(*obstacle))\n",
    "    lines = []\n",
    "    for pol in pols:\n",
    "        boundary = pol.boundary\n",
    "        if boundary.type == 'MultiLineString':\n",
    "            for line in boundary:\n",
    "                lines.append(line)\n",
    "        else:\n",
    "            lines.append(boundary)\n",
    "\n",
    "    MAP = MultiLineString(lines)\n",
    "    return MAP\n",
    "\n",
    "def get_map_arr(MAP_params, shape):\n",
    "    '''\n",
    "    Convert the shapely obstacles into a numpy grid\n",
    "    for use with the A* planner. \n",
    "    \n",
    "    MAP_params is of the form [(xmin, ymin, xmax, ymax), (xmin, ymin, xmax, ymax), ...]\n",
    "    describing each rectangular obstacle in the map. Currently only supports rectangles. \n",
    "    \n",
    "    Shape is just a tuple with the map size. \n",
    "    \n",
    "    '''\n",
    "    map_np = np.zeros(shape)\n",
    "    for param in MAP_params:\n",
    "        xmin, ymin, xmax, ymax = param\n",
    "        map_np[ymin:ymax, xmin:xmax] = 1\n",
    "        \n",
    "    return map_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def synthetic_sensor(MAP, robot_location):\n",
    "    '''\n",
    "    Given a shapely map and the robots current location, \n",
    "    return the 360 degree laser scanner. \n",
    "    '''\n",
    "    lines = []\n",
    "    # 100 is arbitrary radius. Just needs to be big enough to draw line across map. \n",
    "    points = PointsInCircum(100, center = robot_location)\n",
    "    # Create line to all points on circle\n",
    "    for point in points:\n",
    "        A = Point(robot_location)\n",
    "        B = Point(point)\n",
    "        line = LineString([A,B])\n",
    "        lines.append(line)\n",
    "        \n",
    "    # Get points of intersection. \n",
    "    for i, line in enumerate(lines):\n",
    "        # These two types of objects signify multiple intersections. \n",
    "        if type(MAP.intersection(line)) == shapely.geometry.multilinestring.MultiLineString or \\\n",
    "               type(MAP.intersection(line)) == shapely.geometry.multipoint.MultiPoint:\n",
    "            # Get the closest point\n",
    "            temp_dist = []\n",
    "            for point in MAP.intersection(line):\n",
    "#                 try:\n",
    "                temp_dist.append(LineString([robot_location, point]).length)\n",
    "            inter = MAP.intersection(line)[np.argmin(temp_dist)]\n",
    "        # This signifies no intersection. Wont happen on current map. \n",
    "        elif type(MAP.intersection(line)) == shapely.geometry.collection.GeometryCollection:\n",
    "            continue \n",
    "        # One intersection\n",
    "        else:\n",
    "            inter = MAP.intersection(line)\n",
    "        # Create new point and update end point in list of lines. \n",
    "        new_point = (inter.xy[0][0], inter.xy[1][0])\n",
    "        lines[i].coords = [robot_location, new_point]\n",
    "    \n",
    "    # Get lase scan data (distances)\n",
    "    distances = [line.length for line in lines]\n",
    "    return distances[:360]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot(MAP, robot_location, line_strings = None, plot_lines=False):\n",
    "    '''\n",
    "    This plot function is used to show the laser scan lines. \n",
    "    Current not used. Probably will be helpful when creating visualizations. \n",
    "    '''\n",
    "    fig = plt.figure(frameon=False)\n",
    "    fig.set_size_inches(50,50)\n",
    "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "    ax.set_axis_off()\n",
    "    fig.add_axes(ax)\n",
    "    for index, l in enumerate(MAP): \n",
    "        if index != 0:\n",
    "            ax.fill(*l.xy, alpha=1)\n",
    "        else:\n",
    "            ax.plot(*l.xy, alpha=1)\n",
    "    if plot_lines:\n",
    "        for line in line_strings:\n",
    "            ax.plot(*line.xy, alpha=0.25)\n",
    "    ax.scatter(*robot_location, s=30, alpha=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_path(start, goal, arr, plot = True):\n",
    "    '''\n",
    "    Given start (x,y) and goal (x,y) use numpy grid arr\n",
    "    to solve for best path with A*. \n",
    "    \n",
    "    By default, plot the A* path everytime this is called. \n",
    "    '''\n",
    "    resolution = 1\n",
    "    gmap = OccupancyGridMap(arr, resolution)\n",
    "\n",
    "    # 4n = 4 point connectivity. 8N = 8 point connectivity\n",
    "    path, path_px = a_star(start, goal, gmap, movement='4N')\n",
    "    if plot:\n",
    "        gmap.plot()\n",
    "        plot_path(path_px)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_path_(MAP, robot_location, goal_location, path):\n",
    "    '''\n",
    "    Plot path on map using shapely. Not currently used. \n",
    "    '''\n",
    "    fig = plt.figure(frameon=False)\n",
    "    fig.set_size_inches(6,6)\n",
    "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "    fig.add_axes(ax)\n",
    "    \n",
    "    for index, l in enumerate(MAP): \n",
    "        if index != 0:\n",
    "            ax.fill(*l.xy, alpha=1)\n",
    "        else:\n",
    "            ax.plot(*l.xy, alpha=1)\n",
    "    \n",
    "    ax.plot(*LineString(path).xy)\n",
    "    ax.scatter(robot_location[0], robot_location[1], s=30, alpha=1.0) \n",
    "    ax.scatter(goal_location[0], goal_location[1], s=30, alpha=1.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesize_data(start, goal, MAP, map_arr):\n",
    "    '''\n",
    "    synthesize data for one step. \n",
    "    \n",
    "    -Given start and goal, we first get the A* ground truth path. \n",
    "    -If get_path() returns an error, that means there was no path found. \n",
    "    -For each element in the path, use the synthetic sensor to get the readings \n",
    "        the relative goal in odom, and the target movement\n",
    "    '''\n",
    "    \n",
    "    # Get path if one is available\n",
    "    try:\n",
    "        path = get_path(start, goal, map_arr, False)\n",
    "    except:\n",
    "        return\n",
    "    \n",
    "    sensor_readings = []\n",
    "    relative_goals = []\n",
    "    directions = []\n",
    "    prev = start\n",
    "    for i, loc in enumerate(path):\n",
    "        # Get laser scan\n",
    "        sensor_readings.append(synthetic_sensor(MAP, loc))\n",
    "        # Get goal in odom\n",
    "        relative_goals.append((goal[0]-loc[0], goal[1]-loc[1]))\n",
    "        # Get movement to next cell\n",
    "        directions.append((loc[0] - prev[0], loc[1] - prev[1]))\n",
    "        prev=loc\n",
    "    return np.array(sensor_readings), np.array(relative_goals), directions, path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def synthesize_train_set(MAP, map_arr, num_runs = 300):\n",
    "    '''\n",
    "    -Get 'num_runs' different start/goal locations inside the map\n",
    "    -If path is available, get training data for a given path\n",
    "    -Return pandas dataframe where first 360 columns are sensor data, cols\n",
    "     361 and 362 are odom info and then last 2 columns are x,y movement directions. \n",
    "    '''\n",
    "    \n",
    "    df = []\n",
    "    \n",
    "    for i in tqdm(range(num_runs)):\n",
    "        # TODO: Generalize to any map shape\n",
    "        start = (random.randint(1,49), random.randint(1,49))\n",
    "        goal = (random.randint(1,49), random.randint(1,49))\n",
    "        # If path is available, get training info\n",
    "        try:\n",
    "            (sensor_readings, relative_goals, directions, path) = synthesize_data(start, goal, MAP, map_arr)\n",
    "            train = np.concatenate((sensor_readings, relative_goals, directions), axis=1)\n",
    "            df.append(train)\n",
    "        except:\n",
    "            # No path found\n",
    "            continue\n",
    "    return pd.DataFrame(np.vstack(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tuple(x):\n",
    "    '''\n",
    "    Function used to turn 2 pandas columns into\n",
    "    a tuple in one column. See create_classification_problem\n",
    "    for use. \n",
    "    '''\n",
    "    return (x.iloc[0], x.iloc[1])\n",
    "\n",
    "def create_classification_problem(df, one_hot = False):\n",
    "    '''\n",
    "    Now that training data has been synthesized, \n",
    "    prepare data for use with ML model. \n",
    "    '''\n",
    "    \n",
    "    # Turn (x,y) target into into string tuple\n",
    "    # so we can then use label encoding to turn\n",
    "    # this into a classification problem. \n",
    "    df['out'] = df[[362,363]].apply(make_tuple, axis=1)\n",
    "    df['out'] = df['out'].astype(str)\n",
    "    \n",
    "    # Drop the sample where we are at the target location. \n",
    "    # We don't want to learn to stay still. \n",
    "    df = df[df['out']!='(0.0, 0.0)']\n",
    " \n",
    "    # Label encode targets\n",
    "    enc = preprocessing.LabelEncoder()\n",
    "    df['out'] = enc.fit_transform(df['out'])\n",
    "    \n",
    "    # Added one-hot encoding option which\n",
    "    # may be neccessary for some models\n",
    "    if one_hot:\n",
    "        ohe = preprocessing.OneHotEncoder(sparse=False)\n",
    "        ohe.fit(df['out'].values.reshape(-1,1)) \n",
    "        df['out'] = df['out'].apply(lambda x : ohe.transform(x))\n",
    "        df['out'] = df['out'].apply(lambda x : x[0])\n",
    "    \n",
    "    # Drop the (x,y) target columns, which have now\n",
    "    # been label encoded. \n",
    "    df.drop([362, 363], axis=1, inplace=True)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x18f334727b8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18f3143b748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Map obstacles for training map. \n",
    "map_params = [(10, 10, 12, 16), (35,35,48,37), (0,5,8,8), (20,20,25,25), (40,11,49,4), (2,45,14,48), (44,0,49,20)]\n",
    "map_size = (50,50)\n",
    "# Gen training map\n",
    "train_MAP = gen_shapely_map(map_size, map_params)\n",
    "# Convert to numpy array for A*\n",
    "arr = get_map_arr(map_params, map_size)\n",
    "plt.imshow(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create training data\n",
    "df_ = synthesize_train_set(train_MAP, arr)\n",
    "# Prep data for modeling\n",
    "df = create_classification_problem(df_.copy()) \n",
    "# Shuffle data (otherwise model can cheat and memorize order since these are no iid)\n",
    "df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.64172749 0.64455265 0.63702801 0.63414634 0.63658537]\n"
     ]
    }
   ],
   "source": [
    "# Get training acc\n",
    "print(cross_val_score(RandomForestClassifier(n_estimators=50, max_depth=10), pca.fit_transform(df.drop(['out'], axis=1).values), df['out'].values, cv=5, scoring = 'accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model using all data.\n",
    "clf = RandomForestClassifier(n_estimators=50, max_depth=10)\n",
    "clf.fit(df.drop(['out'], axis=1).values, df['out'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "'''\n",
    "Testing Env:\n",
    "\n",
    "Now we use trained model to nav unseen map. \n",
    "'''\n",
    "\n",
    "# Mapping from label encoder (just hard coded it here)\n",
    "dirs = {0:(-1.0, 0.0), 1:(0.0, -1.0), 2:(0.0, 1.0), 3:(1.0, 0.0)}\n",
    "# Create new map with different obstacles\n",
    "map_params = [(20, 20, 22, 29), (30,40,40,49), (2,5,8,8), (0,25,5,29)]\n",
    "test_MAP = gen_shapely_map((50,50), map_params)\n",
    "arr = get_map_arr(map_params, (50,50))\n",
    "\n",
    "\n",
    "def test_on_new_map(test_MAP, test_arr, start, goal, model):\n",
    "    \n",
    "    '''\n",
    "    Test model performance on unseen map. \n",
    "    \n",
    "    test_MAP = shapely map\n",
    "    test_arr = numpy grid of mapll\n",
    "    \n",
    "    start,goal = (x,y), (x,y)\n",
    "    model = trained sklearn model \n",
    "    '''\n",
    "    \n",
    "    # Get ground-truth path\n",
    "    groud_truth = get_path(start, goal, test_arr) \n",
    "    print(\"Number of steps taken in A* Path, \", len(groud_truth))\n",
    "    \n",
    "    # i counter just helps stop after a certain number of steps since\n",
    "    # at the moment the algorithm probably wont reach the goal. \n",
    "    i=0\n",
    "    # Start saving the path traveled\n",
    "    pred_path = [start]\n",
    "    \n",
    "    cur = start\n",
    "    while cur != goal:\n",
    "        # Get the laser_scan data for the current point\n",
    "        laser_scan = synthetic_sensor(test_MAP, cur)\n",
    "#         print(i, laser_scan)\n",
    "        # Add the odom frame goal to the array\n",
    "        laser_scan.append(goal[0]-cur[0])\n",
    "        laser_scan.append(goal[1]-cur[1])\n",
    "        # Create model input\n",
    "        inpX = np.array(laser_scan)\n",
    "        # Get predicted direction\n",
    "        inds = clf.predict_proba(inpX.reshape(1,-1))[0]\n",
    "        best = list(np.argsort(inds))\n",
    "        best.reverse()\n",
    "        \n",
    "        possible_next_states = [(cur[0] + dirs[ind][0], cur[1] + dirs[ind][1]) for ind in best]\n",
    "#         for s in possible_next_states:\n",
    "#             print(s, type(s))\n",
    "#         print(possible_next_states)\n",
    "        temp_states = deepcopy(possible_next_states)\n",
    "        for state in possible_next_states:\n",
    "            if (-1 in state) or (50 in state) or (0 in state) or (state in pred_path):\n",
    "\n",
    "                temp_states.remove(state)\n",
    "\n",
    "        \n",
    "        # Update state\n",
    "        cur = temp_states[0]\n",
    "        assert cur not in pred_path\n",
    "        pred_path.append(cur)\n",
    "        # Cout number of steps traveled \n",
    "        i+=1\n",
    "        if i==100 or cur == goal:\n",
    "            break\n",
    "    \n",
    "    return pred_path \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A* Path\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18f37cb6c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of steps taken in A* Path,  54\n"
     ]
    }
   ],
   "source": [
    "print(\"A* Path\")\n",
    "#4,2 49,40\n",
    "pred_path = test_on_new_map(test_MAP, arr, (10,3), (3,49), clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDHqd9FPTAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18f37c3d518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "OccupancyGridMap(arr, 1).plot()\n",
    "plot_path(pred_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10, 3),\n",
       " (9.0, 3.0),\n",
       " (8.0, 3.0),\n",
       " (7.0, 3.0),\n",
       " (7.0, 2.0),\n",
       " (6.0, 2.0),\n",
       " (6.0, 1.0),\n",
       " (5.0, 1.0),\n",
       " (4.0, 1.0),\n",
       " (3.0, 1.0),\n",
       " (3.0, 2.0),\n",
       " (3.0, 3.0),\n",
       " (3.0, 4.0),\n",
       " (4.0, 4.0),\n",
       " (5.0, 4.0),\n",
       " (6.0, 4.0),\n",
       " (7.0, 4.0),\n",
       " (8.0, 4.0),\n",
       " (8.0, 5.0),\n",
       " (8.0, 6.0),\n",
       " (8.0, 7.0),\n",
       " (8.0, 8.0),\n",
       " (8.0, 9.0),\n",
       " (7.0, 9.0),\n",
       " (6.0, 9.0),\n",
       " (5.0, 9.0),\n",
       " (4.0, 9.0),\n",
       " (3.0, 9.0),\n",
       " (3.0, 10.0),\n",
       " (3.0, 11.0),\n",
       " (3.0, 12.0),\n",
       " (3.0, 13.0),\n",
       " (3.0, 14.0),\n",
       " (3.0, 15.0),\n",
       " (3.0, 16.0),\n",
       " (3.0, 17.0),\n",
       " (3.0, 18.0),\n",
       " (3.0, 19.0),\n",
       " (3.0, 20.0),\n",
       " (3.0, 21.0),\n",
       " (3.0, 22.0),\n",
       " (3.0, 23.0),\n",
       " (3.0, 24.0),\n",
       " (2.0, 24.0),\n",
       " (2.0, 25.0),\n",
       " (1.0, 25.0),\n",
       " (1.0, 26.0),\n",
       " (1.0, 27.0),\n",
       " (1.0, 28.0),\n",
       " (2.0, 28.0),\n",
       " (3.0, 28.0),\n",
       " (4.0, 28.0),\n",
       " (5.0, 28.0),\n",
       " (5.0, 29.0),\n",
       " (4.0, 29.0),\n",
       " (3.0, 29.0),\n",
       " (2.0, 29.0),\n",
       " (1.0, 29.0),\n",
       " (1.0, 30.0),\n",
       " (1.0, 31.0),\n",
       " (1.0, 32.0),\n",
       " (1.0, 33.0),\n",
       " (1.0, 34.0),\n",
       " (1.0, 35.0),\n",
       " (1.0, 36.0),\n",
       " (1.0, 37.0),\n",
       " (1.0, 38.0),\n",
       " (1.0, 39.0),\n",
       " (1.0, 40.0),\n",
       " (1.0, 41.0),\n",
       " (1.0, 42.0),\n",
       " (1.0, 43.0),\n",
       " (1.0, 44.0),\n",
       " (1.0, 45.0),\n",
       " (1.0, 46.0),\n",
       " (1.0, 47.0),\n",
       " (1.0, 48.0),\n",
       " (1.0, 49.0),\n",
       " (2.0, 49.0),\n",
       " (3.0, 49.0)]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Backup Code, was trying to pick second best option if we hit a wall/obstacle \n",
    "\n",
    "#         prediction_probs = list(clf.predict_proba(inpX.reshape(1,-1))[0])\n",
    "#         while len(prediction_probs) > 0:\n",
    "#             best_dir = np.argmax(prediction_probs)\n",
    "#             next_cell_dir = dirs[best_dir]        \n",
    "#             t_cur = (cur[0]-next_cell_dir[0], cur[1]-next_cell_dir[1])\n",
    "#             if any(ele < 0 for ele in t_cur) or any(ele > 50 for ele in t_cur):\n",
    "#                 prediction_probs.remove(max(prediction_probs))\n",
    "#             else:\n",
    "#                 break\n",
    "#         print(best_dir) \n",
    "#         cur = t_cur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = [(1.0,1.0), (2.0,4.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1.0,1.0) in a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
