{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shapely\n",
    "from shapely.geometry import box, MultiPolygon, LineString, Point, MultiLineString, Polygon\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "from gridmap import OccupancyGridMap\n",
    "import matplotlib.pyplot as plt\n",
    "from a_star import a_star\n",
    "from utils import plot_path\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = math.pi\n",
    "def PointsInCircum(r,n=360, center = (0,0)):\n",
    "    return np.array([(center[0] + math.cos(2*pi/n*x)*r, center[1] + math.sin(2*pi/n*x)*r) for x in range(0,n+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_shapely_map(map_size, obstacles):\n",
    "    '''\n",
    "    Given map_size and list of obstacles where\n",
    "    an obstacle is described by a tuple (xmin, ymin, xmax, ymax),\n",
    "    create a shapely map. \n",
    "    '''\n",
    "    \n",
    "    pols = [box(0,0,map_size[0], map_size[1])]\n",
    "    for obstacle in obstacles:\n",
    "        pols.append(box(*obstacle))\n",
    "    lines = []\n",
    "    for pol in pols:\n",
    "        boundary = pol.boundary\n",
    "        if boundary.type == 'MultiLineString':\n",
    "            for line in boundary:\n",
    "                lines.append(line)\n",
    "        else:\n",
    "            lines.append(boundary)\n",
    "\n",
    "    MAP = MultiLineString(lines)\n",
    "    return MAP\n",
    "\n",
    "def get_map_arr(MAP_params, shape):\n",
    "    '''\n",
    "    Convert the shapely obstacles into a numpy grid\n",
    "    for use with the A* planner. \n",
    "    \n",
    "    MAP_params is of the form [(xmin, ymin, xmax, ymax), (xmin, ymin, xmax, ymax), ...]\n",
    "    describing each rectangular obstacle in the map. Currently only supports rectangles. \n",
    "    \n",
    "    Shape is just a tuple with the map size. \n",
    "    \n",
    "    '''\n",
    "    map_np = np.zeros(shape)\n",
    "    for param in MAP_params:\n",
    "        xmin, ymin, xmax, ymax = param\n",
    "        map_np[ymin:ymax, xmin:xmax] = 1\n",
    "        \n",
    "    return map_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthetic_sensor(MAP, robot_location):\n",
    "    '''\n",
    "    Given a shapely map and the robots current location, \n",
    "    return the 360 degree laser scanner. \n",
    "    '''\n",
    "    lines = []\n",
    "    # 100 is arbitrary radius. Just needs to be big enough to draw line across map. \n",
    "    points = PointsInCircum(100, center = robot_location)\n",
    "    # Create line to all points on circle\n",
    "    for point in points:\n",
    "        A = Point(robot_location)\n",
    "        B = Point(point)\n",
    "        line = LineString([A,B])\n",
    "        lines.append(line)\n",
    "        \n",
    "    # Get points of intersection. \n",
    "    for i, line in enumerate(lines):\n",
    "        # These two types of objects signify multiple intersections. \n",
    "        if type(MAP.intersection(line)) == shapely.geometry.multilinestring.MultiLineString or \\\n",
    "               type(MAP.intersection(line)) == shapely.geometry.multipoint.MultiPoint:\n",
    "            # Get the closest point\n",
    "            temp_dist = []\n",
    "            for point in MAP.intersection(line):\n",
    "#                 try:\n",
    "                temp_dist.append(LineString([robot_location, point]).length)\n",
    "            inter = MAP.intersection(line)[np.argmin(temp_dist)]\n",
    "        # This signifies no intersection. Wont happen on current map. \n",
    "        elif type(MAP.intersection(line)) == shapely.geometry.collection.GeometryCollection:\n",
    "            continue \n",
    "        # One intersection\n",
    "        else:\n",
    "            inter = MAP.intersection(line)\n",
    "        # Create new point and update end point in list of lines. \n",
    "        new_point = (inter.xy[0][0], inter.xy[1][0])\n",
    "        lines[i].coords = [robot_location, new_point]\n",
    "    \n",
    "    # Get lase scan data (distances)\n",
    "    distances = [line.length for line in lines]\n",
    "    return distances[:360]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(MAP, robot_location, line_strings = None, plot_lines=False):\n",
    "    '''\n",
    "    This plot function is used to show the laser scan lines. \n",
    "    Current not used. Probably will be helpful when creating visualizations. \n",
    "    '''\n",
    "    fig = plt.figure(frameon=False)\n",
    "    fig.set_size_inches(50,50)\n",
    "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "    ax.set_axis_off()\n",
    "    fig.add_axes(ax)\n",
    "    for index, l in enumerate(MAP): \n",
    "        if index != 0:\n",
    "            ax.fill(*l.xy, alpha=1)\n",
    "        else:\n",
    "            ax.plot(*l.xy, alpha=1)\n",
    "    if plot_lines:\n",
    "        for line in line_strings:\n",
    "            ax.plot(*line.xy, alpha=0.25)\n",
    "    ax.scatter(*robot_location, s=30, alpha=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path(start, goal, arr, plot = True):\n",
    "    '''\n",
    "    Given start (x,y) and goal (x,y) use numpy grid arr\n",
    "    to solve for best path with A*. \n",
    "    \n",
    "    By default, plot the A* path everytime this is called. \n",
    "    '''\n",
    "    resolution = 1\n",
    "    gmap = OccupancyGridMap(arr, resolution)\n",
    "\n",
    "    # 4n = 4 point connectivity. 8N = 8 point connectivity\n",
    "    path, path_px = a_star(start, goal, gmap, movement='4N')\n",
    "    if plot:\n",
    "        gmap.plot()\n",
    "        plot_path(path_px)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_path_(MAP, robot_location, goal_location, path):\n",
    "    '''\n",
    "    Plot path on map using shapely. Not currently used. \n",
    "    '''\n",
    "    fig = plt.figure(frameon=False)\n",
    "    fig.set_size_inches(6,6)\n",
    "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "    fig.add_axes(ax)\n",
    "    \n",
    "    for index, l in enumerate(MAP): \n",
    "        if index != 0:\n",
    "            ax.fill(*l.xy, alpha=1)\n",
    "        else:\n",
    "            ax.plot(*l.xy, alpha=1)\n",
    "    \n",
    "    ax.plot(*LineString(path).xy)\n",
    "    ax.scatter(robot_location[0], robot_location[1], s=30, alpha=1.0) \n",
    "    ax.scatter(goal_location[0], goal_location[1], s=30, alpha=1.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesize_data(start, goal, MAP, map_arr):\n",
    "    '''\n",
    "    synthesize data for one step. \n",
    "    \n",
    "    -Given start and goal, we first get the A* ground truth path. \n",
    "    -If get_path() returns an error, that means there was no path found. \n",
    "    -For each element in the path, use the synthetic sensor to get the readings \n",
    "        the relative goal in odom, and the target movement\n",
    "    '''\n",
    "    \n",
    "    # Get path if one is available\n",
    "    try:\n",
    "        path = get_path(start, goal, map_arr, False)\n",
    "    except:\n",
    "        return\n",
    "    \n",
    "    sensor_readings = []\n",
    "    relative_goals = []\n",
    "    directions = []\n",
    "    prev = start\n",
    "    for i, loc in enumerate(path):\n",
    "        # Get laser scan\n",
    "        sensor_readings.append(synthetic_sensor(MAP, loc))\n",
    "        # Get goal in odom\n",
    "        relative_goals.append((goal[0]-loc[0], goal[1]-loc[1]))\n",
    "        # Get movement to next cell\n",
    "        directions.append((loc[0] - prev[0], loc[1] - prev[1]))\n",
    "        prev=loc\n",
    "    return np.array(sensor_readings), np.array(relative_goals), directions, path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesize_train_set(MAPs, num_runs = 500):\n",
    "    '''\n",
    "    -Get 'num_runs' different start/goal locations inside the map\n",
    "    -If path is available, get training data for a given path\n",
    "    -Return pandas dataframe where first 360 columns are sensor data, cols\n",
    "     361 and 362 are odom info and then last 2 columns are x,y movement directions. \n",
    "    '''\n",
    "    \n",
    "    df = []\n",
    "    \n",
    "    for i in tqdm(range(num_runs)):\n",
    "        # TODO: Generalize to any map shape\n",
    "        start = (random.randint(1,49), random.randint(1,49))\n",
    "        goal = (random.randint(1,49), random.randint(1,49))\n",
    "        MAP, map_arr = random.choice(MAPs)\n",
    "        # If path is available, get training info\n",
    "        try:\n",
    "            (sensor_readings, relative_goals, directions, path) = synthesize_data(start, goal, MAP, map_arr)\n",
    "            train = np.concatenate((sensor_readings, relative_goals, directions), axis=1)\n",
    "            df.append(train)\n",
    "        except:\n",
    "            # No path found\n",
    "            continue\n",
    "    return pd.DataFrame(np.vstack(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tuple(x):\n",
    "    '''\n",
    "    Function used to turn 2 pandas columns into\n",
    "    a tuple in one column. See create_classification_problem\n",
    "    for use. \n",
    "    '''\n",
    "    return (x.iloc[0], x.iloc[1])\n",
    "\n",
    "def create_classification_problem(df, one_hot = False):\n",
    "    '''\n",
    "    Now that training data has been synthesized, \n",
    "    prepare data for use with ML model. \n",
    "    '''\n",
    "    \n",
    "    # Turn (x,y) target into into string tuple\n",
    "    # so we can then use label encoding to turn\n",
    "    # this into a classification problem. \n",
    "    df['out'] = df[[362,363]].apply(make_tuple, axis=1)\n",
    "    df['out'] = df['out'].astype(str)\n",
    "    \n",
    "    # Drop the sample where we are at the target location. \n",
    "    # We don't want to learn to stay still. \n",
    "    df = df[df['out']!='(0.0, 0.0)']\n",
    " \n",
    "    # Label encode targets\n",
    "    enc = preprocessing.LabelEncoder()\n",
    "    df['out'] = enc.fit_transform(df['out'])\n",
    "    \n",
    "    # Added one-hot encoding option which\n",
    "    # may be neccessary for some models\n",
    "    if one_hot:\n",
    "        ohe = preprocessing.OneHotEncoder(sparse=False)\n",
    "        ohe.fit(df['out'].values.reshape(-1,1)) \n",
    "        df['out'] = df['out'].apply(lambda x : ohe.transform(x))\n",
    "        df['out'] = df['out'].apply(lambda x : x[0])\n",
    "    \n",
    "    # Drop the (x,y) target columns, which have now\n",
    "    # been label encoded. \n",
    "    df.drop([362, 363], axis=1, inplace=True)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadFits(map_np, sx, sy, rx, ry, margin):\n",
    "        \"\"\"\n",
    "        looks to see if a quad shape will fit in the grid without colliding with any other tiles\n",
    "        used by placeRoom() and placeRandomRooms()\n",
    "         \n",
    "        Args:\n",
    "            sx and sy: integer, the bottom left coords of the quad to check\n",
    "            rx and ry: integer, the width and height of the quad, where rx > sx and ry > sy\n",
    "            margin: integer, the space in grid cells (ie, 0 = no cells, 1 = 1 cell, 2 = 2 cells) to be away from other tiles on the grid\n",
    "             \n",
    "        returns:\n",
    "            True if the quad fits\n",
    "        \"\"\"\n",
    "         \n",
    "        sx -= margin\n",
    "        sy -= margin\n",
    "        rx += margin*2\n",
    "        ry += margin*2\n",
    "        if sx + rx < np.size(map_np, axis=1) and sy + ry < np.size(map_np, axis=0) and sx >= 0 and sy >= 0:\n",
    "            for x in range(rx):\n",
    "                for y in range(ry):\n",
    "                    if map_np[sy+y, sx+x]: \n",
    "                        return False\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "def placeRandomRooms(map_size, minRoomSize, maxRoomSize, roomStep = 1, margin = 1, attempts = 500):\n",
    "    \"\"\" \n",
    "    randomly places quads in the grid\n",
    "    takes a brute force approach: randomly a generate quad in a random place -> check if fits -> reject if not\n",
    "    Populates self.rooms\n",
    "\n",
    "    Args:\n",
    "        minRoomSize: integer, smallest size of the quad\n",
    "        maxRoomSize: integer, largest the quad can be\n",
    "        roomStep: integer, the amount the room size can grow by, so to get rooms of odd or even numbered sizes set roomSize to 2 and the minSize to odd/even number accordingly\n",
    "        margin: integer, space in grid cells the room needs to be away from other tiles\n",
    "        attempts: the amount of tries to place rooms, larger values will give denser room placements, but slower generation times\n",
    "\n",
    "    Returns:\n",
    "        none\n",
    "    \"\"\"\n",
    "    \n",
    "    pols = [box(0,0,map_size[0], map_size[1])]\n",
    "    map_np = np.zeros(map_size)\n",
    "    \n",
    "    for attempt in range(attempts):\n",
    "        roomWidth = random.randrange(minRoomSize, maxRoomSize, roomStep)\n",
    "        roomHeight = random.randrange(minRoomSize, maxRoomSize, roomStep)\n",
    "        startX = random.randint(0, map_size[1])\n",
    "        startY = random.randint(0, map_size[0])            \n",
    "        if quadFits(map_np, startX, startY, roomWidth, roomHeight, margin):\n",
    "            for x in range(roomWidth):\n",
    "                for y in range(roomHeight):\n",
    "                    map_np[startY+y, startX+x] = 1\n",
    "            pols.append(box(startX, startY, startX+roomWidth, startY+roomHeight))\n",
    "    \n",
    "    lines = []\n",
    "    for pol in pols:\n",
    "        boundary = pol.boundary\n",
    "        if boundary.type == 'MultiLineString':\n",
    "            for line in boundary:\n",
    "                lines.append(line)\n",
    "        else:\n",
    "            lines.append(boundary)\n",
    "\n",
    "    MAP = MultiLineString(lines)\n",
    "    return map_np, MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d7874b55c0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Map obstacles for training map. \n",
    "map_params = [(10, 10, 12, 16), (35,35,48,37), (0,5,8,8), (20,20,25,25), (40,11,49,4), (2,45,14,48), (44,0,49,20)]\n",
    "map_size = (50,50)\n",
    "# Gen training map\n",
    "train_MAP = gen_shapely_map(map_size, map_params)\n",
    "# Convert to numpy array for A*\n",
    "arr = get_map_arr(map_params, map_size)\n",
    "plt.imshow(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d78750c7b8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD6CAYAAABnLjEDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAMTUlEQVR4nO3dXahl5X3H8e+v44yTl4ovVZnOSLVgi7lIFQYr2IuikVoTohcWlFCmMDA3LRgSiJMWCoFemJvoRUvCECVTCNHUBBRJkWGihEAZHV9iNUOcidBmcHDSppLY0olj/r04y3A6nvHsOfvl7H3+3w8c9l5rr33W/yz27zzrefaz9k5VIWnj+431LkDSbBh2qQnDLjVh2KUmDLvUhGGXmhgr7EluTfKjJMeS7J1UUZImL2t9nz3JJuBV4BbgOPAscHdV/fBsz9mS82srH1rT/iSt7n/5b35Zp7LSY+eN8XuvB45V1WsASR4GbgfOGvatfIg/zM1j7FLS+zlUB8/62Din8duBnyxbPj6skzSHxmnZVzpVeE+fIMkeYA/AVj44xu4kjWOcsB8Hrli2vAN4/cyNqmofsA/gglzsRPwVPPn6i1P5vX/y29dO5fdqMY1zGv8scHWSq5JsAe4CHp9MWZImbc0te1WdTvJXwJPAJuChqnplYpVJmqhxTuOpqu8A35lQLZKmyBl0UhNjtezSLE1iILPzoKUtu9SEYZeaMOxSE4ZdasKwS00YdqkJwy41sXDvs0/qopF5er91vWqZ1gU4Z5qnY92ZLbvUhGGXmjDsUhOGXWpi4QboFt1aBsUc4FoyT8dhES/KsWWXmjDsUhOGXWrCsEtNGHapCcMuNWHYpSYMu9SEYZeaMOxSE4ZdasKwS014IUxj83RhyaJZxGNnyy41YdilJgy71IR9dk3dtD7FdhH7zevJll1qwrBLTRh2qYlVw57koSQnk7y8bN3FSQ4kOTrcXjTdMiWNa5QBuq8Bfw/847J1e4GDVXVfkr3D8r2TL296/JRXdbNqy15V3wN+dsbq24H9w/39wB0TrkvShK21z355VZ0AGG4vO9uGSfYkOZzk8NucWuPuJI1r6gN0VbWvqnZW1c7NnD/t3Uk6i7VOqnkjybaqOpFkG3BykkVtZPb7tV7W2rI/Duwa7u8CHptMOZKmZZS33r4B/Avw+0mOJ9kN3AfckuQocMuwLGmOrXoaX1V3n+Whmydci6Qp8kKYOTCrbwR1bsHaTOtCnlFM8vg7XVZqwrBLTRh2qQnDLjVh2KUmDLvUhGGXmjDsUhOGXWrCsEtNGHapCcMuNeGFMJo6L6aZD7bsUhOGXWrCsEtNGHapCQfoGln0gbL1/MSYjcCWXWrCsEtNGHapiYXrsy96v1OLZ6XX3KzGD87czzivf1t2qQnDLjVh2KUmFq7Pvp7W631exyk0CbbsUhOGXWrCsEtNGHapCQfoGpnVV0NrPtmyS00YdqmJVcOe5IokTyU5kuSVJPcM6y9OciDJ0eH2oumXK2mtRumznwY+W1XPJ/lN4LkkB4C/AA5W1X1J9gJ7gXunV6rm1VrGAuz7z96qLXtVnaiq54f7vwCOANuB24H9w2b7gTumVaSk8Z1Tnz3JlcB1wCHg8qo6AUv/EIDLJl2cpMkZOexJPgx8C/h0Vf38HJ63J8nhJIff5tRaapQ0ASOFPclmloL+9ar69rD6jSTbhse3ASdXem5V7auqnVW1czPnT6JmSWuw6gBdkgAPAkeq6kvLHnoc2AXcN9w+NpUKpTm0iAOMo4zG3wj8OfCvSd4ddv1rlkL+zSS7gX8H/mw6JUqahFXDXlXfB3KWh2+ebDmSpsUZdFITXghzDhaxnya9y5ZdasKwS00YdqmJNn32WX0ybMd+fce/eRHZsktNGHapCcMuNWHYpSYMu9SEYZeaMOxSE4ZdamKmk2p+76P/w5NPTn9yi5M8NGuLMGnLll1qwrBLTRh2qYk2F8Jo8ccyFr3+9WbLLjVh2KUmDLvUhGGXmmgzQDfPgzuzmpBxpmkdk0l9hfNGOy7rzZZdasKwS00YdqmJue+zb9T+kzRrtuxSE4ZdasKwS00YdqkJwy41YdilJgy71MSqYU+yNckzSX6Q5JUkXxjWX5XkUJKjSR5JsmX65Upaq1Em1ZwCbqqqt5JsBr6f5J+BzwD3V9XDSb4C7Aa+PMVaNWGL8ImompxVW/Za8tawuHn4KeAm4NFh/X7gjqlUKGkiRuqzJ9mU5EXgJHAA+DHwZlWdHjY5Dmw/y3P3JDmc5PBP//OdSdQsaQ1GCntVvVNV1wI7gOuBa1ba7CzP3VdVO6tq56WXbFp7pZLGck4XwlTVm0meBm4ALkxy3tC67wBeX+35r770Qftv2pAW4XU9ymj8pUkuHO5/APgYcAR4Crhz2GwX8Ni0ipQ0vlFa9m3A/iSbWPrn8M2qeiLJD4GHk/wd8ALw4BTrlDSmVcNeVS8B162w/jWW+u+SFoAz6KQm5v6TatZiUp9uKm0ktuxSE4ZdasKwS01syD77otlo4wVnjpmMMoay0Y7BKCZ1IdKox86WXWrCsEtNGHapCfvsE+YHQkxOh79xlmzZpSYMu9SEYZeaMOxSE4ZdasKwS00YdqkJwy41sSEn1TgZQ9M2iclTs36d2rJLTRh2qQnDLjVh2KUmDLvUhGGXmjDsUhOGXWpiQ06qWU9O6NG8smWXmjDsUhOGXWqibZ99o33T60b7e9ZqGp/uu1GOky271IRhl5oYOexJNiV5IckTw/JVSQ4lOZrkkSRbplempHGdS5/9HuAIcMGw/EXg/qp6OMlXgN3Al89l57P+FstJm9a3v8xTH7HD39jFSC17kh3Ax4GvDssBbgIeHTbZD9wxjQIlTcaop/EPAJ8DfjUsXwK8WVWnh+XjwPaVnphkT5LDSQ6/zamxipW0dquGPckngJNV9dzy1StsWis9v6r2VdXOqtq5mfPXWKakcY3SZ78R+GSS24CtLPXZHwAuTHLe0LrvAF6fXpmSxrVqy15Vn6+qHVV1JXAX8N2q+hTwFHDnsNku4LGpVSlpbOO8z34v8Jkkx1jqwz84mZIkTcM5TZetqqeBp4f7rwHXT74kSdPgDDqpibYXwjipQ93YsktNGHapCcMuNdG2zy6NYxHHfGzZpSYMu9SEYZeaMOxSEw7QbRCLOGA0DR6Hs7Nll5ow7FIThl1qwj673pd94I3Dll1qwrBLTRh2qQnDLjVh2KUmDLvUhGGXmjDsUhPrOqlm0SdsLHr96sWWXWrCsEtNGHapCcMuNWHYpSYMu9SEYZeaMOxSE4ZdasKwS00YdqkJwy41kaqa3c6SnwL/BvwW8B8z2/F4FqlWWKx6F6lWWIx6f6eqLl3pgZmG/dc7TQ5X1c6Z73gNFqlWWKx6F6lWWLx6z+RpvNSEYZeaWK+w71un/a7FItUKi1XvItUKi1fv/7MufXZJs+dpvNTETMOe5NYkP0pyLMneWe57FEkeSnIyycvL1l2c5ECSo8PtRetZ47uSXJHkqSRHkryS5J5h/bzWuzXJM0l+MNT7hWH9VUkODfU+kmTLetf6riSbkryQ5IlheW5rHcXMwp5kE/APwJ8CHwHuTvKRWe1/RF8Dbj1j3V7gYFVdDRwclufBaeCzVXUNcAPwl8PxnNd6TwE3VdUfANcCtya5AfgicP9Q738Bu9exxjPdAxxZtjzPta5qli379cCxqnqtqn4JPAzcPsP9r6qqvgf87IzVtwP7h/v7gTtmWtRZVNWJqnp+uP8Lll6U25nfequq3hoWNw8/BdwEPDqsn5t6k+wAPg58dVgOc1rrqGYZ9u3AT5YtHx/WzbvLq+oELAUMuGyd63mPJFcC1wGHmON6h9PiF4GTwAHgx8CbVXV62GSeXhMPAJ8DfjUsX8L81jqSWYY9K6zzrYAxJfkw8C3g01X18/Wu5/1U1TtVdS2wg6UzvWtW2my2Vb1Xkk8AJ6vqueWrV9h03Ws9F7P8kojjwBXLlncAr89w/2v1RpJtVXUiyTaWWqW5kGQzS0H/elV9e1g9t/W+q6reTPI0S2MNFyY5b2gx5+U1cSPwySS3AVuBC1hq6eex1pHNsmV/Frh6GNHcAtwFPD7D/a/V48Cu4f4u4LF1rOXXhj7kg8CRqvrSsofmtd5Lk1w43P8A8DGWxhmeAu4cNpuLeqvq81W1o6quZOl1+t2q+hRzWOs5qaqZ/QC3Aa+y1Ff7m1nue8T6vgGcAN5m6UxkN0t9tYPA0eH24vWuc6j1j1g6jXwJeHH4uW2O6/0o8MJQ78vA3w7rfxd4BjgG/BNw/nrXekbdfww8sQi1rvbjDDqpCWfQSU0YdqkJwy41YdilJgy71IRhl5ow7FIThl1q4v8AmEuMJUuhspgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "map_size = (50,50)\n",
    "# Refer here https://whatjaysaid.wordpress.com/2016/01/15/1228/\n",
    "arr1, train_MAP1 = placeRandomRooms(map_size, minRoomSize=3, maxRoomSize=8, roomStep = 1, margin = 0, attempts = 200)\n",
    "plt.imshow(arr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d787561fd0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "map_size = (50,50)\n",
    "arr2, train_MAP2 = placeRandomRooms(map_size, minRoomSize=10, maxRoomSize=15, roomStep = 1, margin = 0, attempts =50)\n",
    "plt.imshow(arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d7875b95c0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "map_size = (50,50)\n",
    "arr3, train_MAP3 = placeRandomRooms(map_size, minRoomSize=3, maxRoomSize=20, roomStep = 1, margin = 0, attempts = 80)\n",
    "plt.imshow(arr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPS = [(train_MAP1, arr1), (train_MAP2,arr2), (train_MAP3, arr3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [08:00<00:00,  4.80s/it]\n"
     ]
    }
   ],
   "source": [
    "# Create training data\n",
    "df_ = synthesize_train_set(MAPS, num_runs=100)\n",
    "# Prep data for modeling\n",
    "df = create_classification_problem(df_.copy()) \n",
    "# Shuffle data (otherwise model can cheat and memorize order since these are no iid)\n",
    "df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1496, 363)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('500_run_multimap.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('500_run_multimap.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['out'].values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = np.expand_dims(df['out'].values, axis=1)\n",
    "tmp = to_categorical(tmp)\n",
    "print(tmp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = np.array([[0., 1., 0., 0.],\n",
    " [0., 0., 1., 0.],\n",
    " [0., 0., 1., 0.],\n",
    " [0., 0., 1., 0.],\n",
    " [0., 1., 0., 0.]])\n",
    "tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85345512 0.84187525 0.86441352]\n"
     ]
    }
   ],
   "source": [
    "# Get training acc\n",
    "# pca = PCA()\n",
    "# print(cross_val_score(RandomForestClassifier(n_estimators=50, max_depth=10), pca.fit_transform(df.drop(['out'], axis=1).values), df['out'].values, cv=5, scoring = 'accuracy'))\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "print(cross_val_score(RandomForestClassifier(n_estimators=100, max_depth=36), df.drop(['out'], axis=1).values, df['out'].values, cv=3, scoring = 'accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=36, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model using all data.\n",
    "clf = RandomForestClassifier(n_estimators=150, max_depth=36)\n",
    "clf.fit(df.drop(['out'], axis=1).values, df['out'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic NN\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense# Neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=363, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "history = model.fit(df.drop(['out'], axis=1).values, tmp, epochs=100, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d787324860>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "map_size = (50,50)\n",
    "# Refer here https://whatjaysaid.wordpress.com/2016/01/15/1228/\n",
    "arr, test_MAP = placeRandomRooms(map_size, minRoomSize=3, maxRoomSize=15, roomStep = 1, margin = 0, attempts = 100)\n",
    "plt.imshow(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN test\n",
    "from copy import deepcopy\n",
    "'''\n",
    "Testing Env:\n",
    "\n",
    "Now we use trained model to nav unseen map. \n",
    "'''\n",
    "\n",
    "# Mapping from label encoder (just hard coded it here)\n",
    "dirs = {0:(-1.0, 0.0), 1:(0.0, -1.0), 2:(0.0, 1.0), 3:(1.0, 0.0)}\n",
    "# Create new map with different obstacles\n",
    "# map_params = [(20, 20, 22, 29), (30,40,40,49), (2,5,8,8), (0,25,5,29)]\n",
    "# test_MAP = gen_shapely_map((50,50), map_params)\n",
    "# arr = get_map_arr(map_params, (50,50))\n",
    "\n",
    "\n",
    "def test_on_new_map(test_MAP, test_arr, start, goal, model):\n",
    "    \n",
    "    '''\n",
    "    Test model performance on unseen map. \n",
    "    \n",
    "    test_MAP = shapely map\n",
    "    test_arr = numpy grid of mapll\n",
    "    \n",
    "    start,goal = (x,y), (x,y)\n",
    "    model = trained sklearn model \n",
    "    '''\n",
    "    \n",
    "    # Get ground-truth path\n",
    "    groud_truth = get_path(start, goal, test_arr) \n",
    "    print(\"Number of steps taken in A* Path, \", len(groud_truth))\n",
    "    \n",
    "    # i counter just helps stop after a certain number of steps since\n",
    "    # at the moment the algorithm probably wont reach the goal. \n",
    "    i=0\n",
    "    # Start saving the path traveled\n",
    "    pred_path = [start]\n",
    "    \n",
    "    cur = start\n",
    "    while cur != goal:\n",
    "        # Get the laser_scan data for the current point\n",
    "        laser_scan = synthetic_sensor(test_MAP, cur)\n",
    "#         print(i, laser_scan)\n",
    "        # Add the odom frame goal to the array\n",
    "        laser_scan.append(goal[0]-cur[0])\n",
    "        laser_scan.append(goal[1]-cur[1])\n",
    "        # Create model input\n",
    "        inpX = np.array(laser_scan)\n",
    "        # Get predicted direction\n",
    "#         inds = clf.predict_proba(inpX.reshape(1,-1))[0]\n",
    "        \n",
    "        inds = model.predict(inpX.reshape(1,-1))\n",
    "        #Converting predictions to label\n",
    "        pred = list()\n",
    "        for i in range(len(y_pred)):\n",
    "            pred.append(np.argmax(y_pred[i]))\n",
    "        #Converting one hot encoded test label to label\n",
    "        test = list()\n",
    "        for i in range(len(y_test)):\n",
    "            test.append(np.argmax(y_test[i]))\n",
    "    \n",
    "        best = list(np.argsort(inds))\n",
    "        best.reverse()\n",
    "        \n",
    "        possible_next_states = [(cur[0] + dirs[ind][0], cur[1] + dirs[ind][1]) for ind in best]\n",
    "#         for s in possible_next_states:\n",
    "#             print(s, type(s))\n",
    "#         print(possible_next_states)\n",
    "        temp_states = deepcopy(possible_next_states)\n",
    "        for state in possible_next_states:\n",
    "            if (-1 in state) or (50 in state) or (0 in state) or (state in pred_path):\n",
    "\n",
    "                temp_states.remove(state)\n",
    "\n",
    "        \n",
    "        # Update state\n",
    "        cur = temp_states[0]\n",
    "        assert cur not in pred_path\n",
    "        pred_path.append(cur)\n",
    "        # Cout number of steps traveled \n",
    "        i+=1\n",
    "        if i==100 or cur == goal:\n",
    "            break\n",
    "    \n",
    "    return pred_path \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import sys\n",
    "'''\n",
    "Testing Env:\n",
    "\n",
    "Now we use trained model to nav unseen map. \n",
    "'''\n",
    "\n",
    "# Mapping from label encoder (just hard coded it here)\n",
    "dirs = {0:(-1.0, 0.0), 1:(0.0, -1.0), 2:(0.0, 1.0), 3:(1.0, 0.0)}\n",
    "# Create new map with different obstacles\n",
    "# map_params = [(20, 20, 22, 29), (30,40,40,49), (2,5,8,8), (0,25,5,29)]\n",
    "# test_MAP = gen_shapely_map((50,50), map_params)\n",
    "# arr = get_map_arr(map_params, (50,50))\n",
    "\n",
    "\n",
    "def test_on_new_map(test_MAP, test_arr, start, goal, clf):\n",
    "    \n",
    "    '''\n",
    "    Test model performance on unseen map. \n",
    "    \n",
    "    test_MAP = shapely map\n",
    "    test_arr = numpy grid of mapll\n",
    "    \n",
    "    start,goal = (x,y), (x,y)\n",
    "    model = trained sklearn model \n",
    "    '''\n",
    "    \n",
    "    # Get ground-truth path\n",
    "    groud_truth = get_path(start, goal, test_arr) \n",
    "    print(\"Number of steps taken in A* Path, \", len(groud_truth))\n",
    "    \n",
    "    # i counter just helps stop after a certain number of steps since\n",
    "    # at the moment the algorithm probably wont reach the goal. \n",
    "    i=0\n",
    "    # Start saving the path traveled\n",
    "    pred_path = [start]\n",
    "    \n",
    "    cur = start\n",
    "    while cur != goal:\n",
    "        # Get the laser_scan data for the current point\n",
    "        laser_scan = synthetic_sensor(test_MAP, cur)\n",
    "#         print(i, laser_scan)\n",
    "        # Add the odom frame goal to the array\n",
    "        laser_scan.append(goal[0]-cur[0])\n",
    "        laser_scan.append(goal[1]-cur[1])\n",
    "        # Create model input\n",
    "        inpX = np.array(laser_scan)\n",
    "        # Get predicted direction\n",
    "        print(clf.predict_proba(inpX.reshape(1,-1)))\n",
    "        print(clf.predict_proba(inpX.reshape(1,-1)).shape)\n",
    "        sys.exit()\n",
    "        inds = clf.predict_proba(inpX.reshape(1,-1))[0]\n",
    "        best = list(np.argsort(inds))\n",
    "        best.reverse()\n",
    "        \n",
    "        possible_next_states = [(cur[0] + dirs[ind][0], cur[1] + dirs[ind][1]) for ind in best]\n",
    "#         for s in possible_next_states:\n",
    "#             print(s, type(s))\n",
    "#         print(possible_next_states)\n",
    "        temp_states = deepcopy(possible_next_states)\n",
    "        for state in possible_next_states:\n",
    "            if (-1 in state) or (50 in state) or (0 in state) or (state in pred_path):\n",
    "\n",
    "                temp_states.remove(state)\n",
    "\n",
    "        \n",
    "        # Update state\n",
    "        cur = temp_states[0]\n",
    "        assert cur not in pred_path\n",
    "        pred_path.append(cur)\n",
    "        # Cout number of steps traveled \n",
    "        i+=1\n",
    "        if i==100 or cur == goal:\n",
    "            break\n",
    "    \n",
    "    return pred_path \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A* Path\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of steps taken in A* Path,  6\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'LineString' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\shapely\\speedups\\_speedups.pyx\u001b[0m in \u001b[0;36mshapely.speedups._speedups.geos_linestring_from_py\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute '__array_interface__'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-d61535051fa7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"A* Path\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#4,2 49,40\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpred_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_on_new_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_MAP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-25-0f6dd7af3210>\u001b[0m in \u001b[0;36mtest_on_new_map\u001b[1;34m(test_MAP, test_arr, start, goal, clf)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mcur\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mgoal\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;31m# Get the laser_scan data for the current point\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0mlaser_scan\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msynthetic_sensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_MAP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcur\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;31m#         print(i, laser_scan)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;31m# Add the odom frame goal to the array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-20a282e486c0>\u001b[0m in \u001b[0;36msynthetic_sensor\u001b[1;34m(MAP, robot_location)\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mpoint\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mMAP\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m#                 try:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m                 \u001b[0mtemp_dist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLineString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrobot_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpoint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m             \u001b[0minter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMAP\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_dist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;31m# This signifies no intersection. Wont happen on current map.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\shapely\\geometry\\linestring.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, coordinates)\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mBaseGeometry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcoordinates\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_coords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoordinates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\shapely\\geometry\\linestring.py\u001b[0m in \u001b[0;36m_set_coords\u001b[1;34m(self, coordinates)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set_coords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoordinates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgeos_linestring_from_py\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoordinates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_geom\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\shapely\\speedups\\_speedups.pyx\u001b[0m in \u001b[0;36mshapely.speedups._speedups.geos_linestring_from_py\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'LineString' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "print(\"A* Path\")\n",
    "#4,2 49,40\n",
    "pred_path = test_on_new_map(test_MAP, arr, (0,0), (0,5), clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"A* Path\")\n",
    "#4,2 49,40\n",
    "pred_path = test_on_new_map(test_MAP, arr, (3,10), (36,38), clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"A* Path\")\n",
    "#4,2 49,40\n",
    "pred_path = test_on_new_map(test_MAP, arr, (3,10), (40,15), clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OccupancyGridMap(arr, 1).plot()\n",
    "# plt.imshow(arr)\n",
    "plot_path(pred_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backup Code, was trying to pick second best option if we hit a wall/obstacle \n",
    "\n",
    "#         prediction_probs = list(clf.predict_proba(inpX.reshape(1,-1))[0])\n",
    "#         while len(prediction_probs) > 0:\n",
    "#             best_dir = np.argmax(prediction_probs)\n",
    "#             next_cell_dir = dirs[best_dir]        \n",
    "#             t_cur = (cur[0]-next_cell_dir[0], cur[1]-next_cell_dir[1])\n",
    "#             if any(ele < 0 for ele in t_cur) or any(ele > 50 for ele in t_cur):\n",
    "#                 prediction_probs.remove(max(prediction_probs))\n",
    "#             else:\n",
    "#                 break\n",
    "#         print(best_dir) \n",
    "#         cur = t_cur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [(1.0,1.0), (2.0,4.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1.0,1.0) in a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pypng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
