{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joega\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import shapely\n",
    "from shapely.geometry import box, MultiPolygon, LineString, Point, MultiLineString, Polygon\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "from gridmap import OccupancyGridMap\n",
    "import matplotlib.pyplot as plt\n",
    "from a_star import a_star\n",
    "from utils import plot_path\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pi = math.pi\n",
    "def PointsInCircum(r,n=360, center = (0,0)):\n",
    "    return np.array([(center[0] + math.cos(2*pi/n*x)*r, center[1] + math.sin(2*pi/n*x)*r) for x in range(0,n+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_shapely_map(map_size, obstacles):\n",
    "    '''\n",
    "    Given map_size and list of obstacles where\n",
    "    an obstacle is described by a tuple (xmin, ymin, xmax, ymax),\n",
    "    create a shapely map. \n",
    "    '''\n",
    "    \n",
    "    pols = [box(0,0,map_size[0], map_size[1])]\n",
    "    for obstacle in obstacles:\n",
    "        pols.append(box(*obstacle))\n",
    "    lines = []\n",
    "    for pol in pols:\n",
    "        boundary = pol.boundary\n",
    "        if boundary.type == 'MultiLineString':\n",
    "            for line in boundary:\n",
    "                lines.append(line)\n",
    "        else:\n",
    "            lines.append(boundary)\n",
    "\n",
    "    MAP = MultiLineString(lines)\n",
    "    return MAP\n",
    "\n",
    "def get_map_arr(MAP_params, shape):\n",
    "    '''\n",
    "    Convert the shapely obstacles into a numpy grid\n",
    "    for use with the A* planner. \n",
    "    \n",
    "    MAP_params is of the form [(xmin, ymin, xmax, ymax), (xmin, ymin, xmax, ymax), ...]\n",
    "    describing each rectangular obstacle in the map. Currently only supports rectangles. \n",
    "    \n",
    "    Shape is just a tuple with the map size. \n",
    "    \n",
    "    '''\n",
    "    map_np = np.zeros(shape)\n",
    "    for param in MAP_params:\n",
    "        xmin, ymin, xmax, ymax = param\n",
    "        map_np[ymin:ymax, xmin:xmax] = 1\n",
    "        \n",
    "    return map_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def synthetic_sensor(MAP, robot_location):\n",
    "    '''\n",
    "    Given a shapely map and the robots current location, \n",
    "    return the 360 degree laser scanner. \n",
    "    '''\n",
    "    lines = []\n",
    "    # 100 is arbitrary radius. Just needs to be big enough to draw line across map. \n",
    "    points = PointsInCircum(100, center = robot_location)\n",
    "    # Create line to all points on circle\n",
    "    for point in points:\n",
    "        A = Point(robot_location)\n",
    "        B = Point(point)\n",
    "        line = LineString([A,B])\n",
    "        lines.append(line)\n",
    "        \n",
    "    # Get points of intersection. \n",
    "    for i, line in enumerate(lines):\n",
    "        # These two types of objects signify multiple intersections. \n",
    "        if type(MAP.intersection(line)) == shapely.geometry.multilinestring.MultiLineString or \\\n",
    "               type(MAP.intersection(line)) == shapely.geometry.multipoint.MultiPoint:\n",
    "            # Get the closest point\n",
    "            temp_dist = []\n",
    "            for point in MAP.intersection(line):\n",
    "#                 try:\n",
    "                temp_dist.append(LineString([robot_location, point]).length)\n",
    "            inter = MAP.intersection(line)[np.argmin(temp_dist)]\n",
    "        # This signifies no intersection. Wont happen on current map. \n",
    "        elif type(MAP.intersection(line)) == shapely.geometry.collection.GeometryCollection:\n",
    "            continue \n",
    "        # One intersection\n",
    "        else:\n",
    "            inter = MAP.intersection(line)\n",
    "        # Create new point and update end point in list of lines. \n",
    "        new_point = (inter.xy[0][0], inter.xy[1][0])\n",
    "        lines[i].coords = [robot_location, new_point]\n",
    "    \n",
    "    # Get lase scan data (distances)\n",
    "    distances = [line.length for line in lines]\n",
    "    return distances[:360]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot(MAP, robot_location, line_strings = None, plot_lines=False):\n",
    "    '''\n",
    "    This plot function is used to show the laser scan lines. \n",
    "    Current not used. Probably will be helpful when creating visualizations. \n",
    "    '''\n",
    "    fig = plt.figure(frameon=False)\n",
    "    fig.set_size_inches(50,50)\n",
    "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "    ax.set_axis_off()\n",
    "    fig.add_axes(ax)\n",
    "    for index, l in enumerate(MAP): \n",
    "        if index != 0:\n",
    "            ax.fill(*l.xy, alpha=1)\n",
    "        else:\n",
    "            ax.plot(*l.xy, alpha=1)\n",
    "    if plot_lines:\n",
    "        for line in line_strings:\n",
    "            ax.plot(*line.xy, alpha=0.25)\n",
    "    ax.scatter(*robot_location, s=30, alpha=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_path(start, goal, arr, plot = True):\n",
    "    '''\n",
    "    Given start (x,y) and goal (x,y) use numpy grid arr\n",
    "    to solve for best path with A*. \n",
    "    \n",
    "    By default, plot the A* path everytime this is called. \n",
    "    '''\n",
    "    resolution = 1\n",
    "    gmap = OccupancyGridMap(arr, resolution)\n",
    "\n",
    "    # 4n = 4 point connectivity. 8N = 8 point connectivity\n",
    "    path, path_px = a_star(start, goal, gmap, movement='4N')\n",
    "    if plot:\n",
    "        gmap.plot()\n",
    "        plot_path(path_px)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_path_(MAP, robot_location, goal_location, path):\n",
    "    '''\n",
    "    Plot path on map using shapely. Not currently used. \n",
    "    '''\n",
    "    fig = plt.figure(frameon=False)\n",
    "    fig.set_size_inches(6,6)\n",
    "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "    fig.add_axes(ax)\n",
    "    \n",
    "    for index, l in enumerate(MAP): \n",
    "        if index != 0:\n",
    "            ax.fill(*l.xy, alpha=1)\n",
    "        else:\n",
    "            ax.plot(*l.xy, alpha=1)\n",
    "    \n",
    "    ax.plot(*LineString(path).xy)\n",
    "    ax.scatter(robot_location[0], robot_location[1], s=30, alpha=1.0) \n",
    "    ax.scatter(goal_location[0], goal_location[1], s=30, alpha=1.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesize_data(start, goal, MAP, map_arr):\n",
    "    '''\n",
    "    synthesize data for one step. \n",
    "    \n",
    "    -Given start and goal, we first get the A* ground truth path. \n",
    "    -If get_path() returns an error, that means there was no path found. \n",
    "    -For each element in the path, use the synthetic sensor to get the readings \n",
    "        the relative goal in odom, and the target movement\n",
    "    '''\n",
    "    \n",
    "    # Get path if one is available\n",
    "    try:\n",
    "        path = get_path(start, goal, map_arr, False)\n",
    "    except:\n",
    "        return\n",
    "    \n",
    "    sensor_readings = []\n",
    "    relative_goals = []\n",
    "    directions = []\n",
    "    prev = start\n",
    "    for i, loc in enumerate(path):\n",
    "        # Get laser scan\n",
    "        sensor_readings.append(synthetic_sensor(MAP, loc))\n",
    "        # Get goal in odom\n",
    "        relative_goals.append((goal[0]-loc[0], goal[1]-loc[1]))\n",
    "        # Get movement to next cell\n",
    "        directions.append((loc[0] - prev[0], loc[1] - prev[1]))\n",
    "        prev=loc\n",
    "    return np.array(sensor_readings), np.array(relative_goals), directions, path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def synthesize_train_set(MAP, map_arr, num_runs = 300):\n",
    "    '''\n",
    "    -Get 'num_runs' different start/goal locations inside the map\n",
    "    -If path is available, get training data for a given path\n",
    "    -Return pandas dataframe where first 360 columns are sensor data, cols\n",
    "     361 and 362 are odom info and then last 2 columns are x,y movement directions. \n",
    "    '''\n",
    "    \n",
    "    df = []\n",
    "    \n",
    "    for i in tqdm(range(num_runs)):\n",
    "        # TODO: Generalize to any map shape\n",
    "        start = (random.randint(1,49), random.randint(1,49))\n",
    "        goal = (random.randint(1,49), random.randint(1,49))\n",
    "        # If path is available, get training info\n",
    "        try:\n",
    "            (sensor_readings, relative_goals, directions, path) = synthesize_data(start, goal, MAP, map_arr)\n",
    "            train = np.concatenate((sensor_readings, relative_goals, directions), axis=1)\n",
    "            df.append(train)\n",
    "        except:\n",
    "            # No path found\n",
    "            continue\n",
    "    return pd.DataFrame(np.vstack(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tuple(x):\n",
    "    '''\n",
    "    Function used to turn 2 pandas columns into\n",
    "    a tuple in one column. See create_classification_problem\n",
    "    for use. \n",
    "    '''\n",
    "    return (x.iloc[0], x.iloc[1])\n",
    "\n",
    "def create_classification_problem(df, one_hot = False):\n",
    "    '''\n",
    "    Now that training data has been synthesized, \n",
    "    prepare data for use with ML model. \n",
    "    '''\n",
    "    \n",
    "    # Turn (x,y) target into into string tuple\n",
    "    # so we can then use label encoding to turn\n",
    "    # this into a classification problem. \n",
    "    df['out'] = df[[362,363]].apply(make_tuple, axis=1)\n",
    "    df['out'] = df['out'].astype(str)\n",
    "    \n",
    "    # Drop the sample where we are at the target location. \n",
    "    # We don't want to learn to stay still. \n",
    "    df = df[df['out']!='(0.0, 0.0)']\n",
    " \n",
    "    # Label encode targets\n",
    "    enc = preprocessing.LabelEncoder()\n",
    "    df['out'] = enc.fit_transform(df['out'])\n",
    "    \n",
    "    # Added one-hot encoding option which\n",
    "    # may be neccessary for some models\n",
    "    if one_hot:\n",
    "        ohe = preprocessing.OneHotEncoder(sparse=False)\n",
    "        ohe.fit(df['out'].values.reshape(-1,1)) \n",
    "        df['out'] = df['out'].apply(lambda x : ohe.transform(x))\n",
    "        df['out'] = df['out'].apply(lambda x : x[0])\n",
    "    \n",
    "    # Drop the (x,y) target columns, which have now\n",
    "    # been label encoded. \n",
    "    df.drop([362, 363], axis=1, inplace=True)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x18f334727b8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18f3143b748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Map obstacles for training map. \n",
    "map_params = [(10, 10, 12, 16), (35,35,48,37), (0,5,8,8), (20,20,25,25), (40,11,49,4), (2,45,14,48), (44,0,49,20)]\n",
    "map_size = (50,50)\n",
    "# Gen training map\n",
    "train_MAP = gen_shapely_map(map_size, map_params)\n",
    "# Convert to numpy array for A*\n",
    "arr = get_map_arr(map_params, map_size)\n",
    "plt.imshow(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 300/300 [50:25<00:00, 10.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.79708384 0.80072904 0.8163017  0.83434836 0.77953715 0.77101096\n",
      " 0.82926829 0.7695122  0.76434676 0.7997558 ]\n"
     ]
    }
   ],
   "source": [
    "# Create training data\n",
    "df_ = synthesize_train_set(train_MAP, arr)\n",
    "\n",
    "# Prep data for modeling\n",
    "df = create_classification_problem(df_.copy()) \n",
    "# Shuffle data (otherwise model can cheat and memorize order since these are no iid)\n",
    "df = df.sample(frac=1)\n",
    "# Get training acc\n",
    "print(cross_val_score(RandomForestClassifier(), df.drop(['out'], axis=1).values, df['out'].values, cv=10, scoring = 'accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model using all data.\n",
    "clf = RandomForestClassifier(max_depth=10)\n",
    "clf.fit(df.drop(['out'], axis=1).values, df['out'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Testing Env:\n",
    "\n",
    "Now we use trained model to nav unseen map. \n",
    "'''\n",
    "\n",
    "# Mapping from label encoder (just hard coded it here)\n",
    "dirs = {0:(-1.0, 0.0), 1:(0.0, -1.0), 2:(0.0, 1.0), 3:(1.0, 0.0)}\n",
    "# Create new map with different obstacles\n",
    "map_params = [(20, 20, 22, 29), (30,40,40,50), (0,5,8,8)]\n",
    "test_MAP = gen_shapely_map((50,50), map_params)\n",
    "arr = get_map_arr(map_params, (50,50))\n",
    "\n",
    "\n",
    "def test_on_new_map(test_MAP, test_arr, start, goal, model):\n",
    "    \n",
    "    '''\n",
    "    Test model performance on unseen map. \n",
    "    \n",
    "    test_MAP = shapely map\n",
    "    test_arr = numpy grid of mapll\n",
    "    \n",
    "    start,goal = (x,y), (x,y)\n",
    "    model = trained sklearn model \n",
    "    '''\n",
    "    \n",
    "    # Get ground-truth path\n",
    "    groud_truth = get_path(start, goal, test_arr) \n",
    "    print(\"Number of steps taken in A* Path, \", len(groud_truth))\n",
    "    \n",
    "    # i counter just helps stop after a certain number of steps since\n",
    "    # at the moment the algorithm probably wont reach the goal. \n",
    "    i=0\n",
    "    # Start saving the path traveled\n",
    "    pred_path = [start]\n",
    "    \n",
    "    cur = start\n",
    "    while cur != goal:\n",
    "        # Get the laser_scan data for the current point\n",
    "        laser_scan = synthetic_sensor(test_MAP, cur)\n",
    "        # Add the odom frame goal to the array\n",
    "        laser_scan.append(goal[0]-cur[0])\n",
    "        laser_scan.append(goal[1]-cur[1])\n",
    "        # Create model input\n",
    "        inpX = np.array(laser_scan)\n",
    "        # Get predicted direction\n",
    "#         ind = clf.predict(inpX.reshape(1,-1))[0]\n",
    "        inds = clf.predict_proba(inpX.reshape(1,-1))[0]\n",
    "        best = list(np.argsort(inds))\n",
    "        best.reverse()\n",
    "        \n",
    "        possible_next_states = [(cur[0] + dirs[ind][0], cur[1] + dirs[ind][1]) for ind in best]\n",
    "        for state in possible_next_states:\n",
    "            if -1 in state or 50 in state or state in pred_path:\n",
    "                possible_next_states.remove(state)\n",
    "        \n",
    "        # Update state\n",
    "        cur = possible_next_states[0]\n",
    "        pred_path.append(cur)\n",
    "        # Cout number of steps traveled \n",
    "        i+=1\n",
    "        if i==100:\n",
    "            break\n",
    "    \n",
    "    return pred_path \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A* Path\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18f3752fc50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of steps taken in A* Path,  25\n"
     ]
    }
   ],
   "source": [
    "print(\"A* Path\")\n",
    "pred_path = test_on_new_map(test_MAP, arr, (4,2), (10,20), clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nw5cK+n9rIIqkK9DZlwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18f37509f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "OccupancyGridMap(arr, 1).plot()\n",
    "plot_path(pred_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Backup Code, was trying to pick second best option if we hit a wall/obstacle \n",
    "\n",
    "#         prediction_probs = list(clf.predict_proba(inpX.reshape(1,-1))[0])\n",
    "#         while len(prediction_probs) > 0:\n",
    "#             best_dir = np.argmax(prediction_probs)\n",
    "#             next_cell_dir = dirs[best_dir]        \n",
    "#             t_cur = (cur[0]-next_cell_dir[0], cur[1]-next_cell_dir[1])\n",
    "#             if any(ele < 0 for ele in t_cur) or any(ele > 50 for ele in t_cur):\n",
    "#                 prediction_probs.remove(max(prediction_probs))\n",
    "#             else:\n",
    "#                 break\n",
    "#         print(best_dir) \n",
    "#         cur = t_cur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
