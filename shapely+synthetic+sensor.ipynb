{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joega\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import shapely\n",
    "from shapely.geometry import box, MultiPolygon, LineString, Point, MultiLineString, Polygon\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "from gridmap import OccupancyGridMap\n",
    "import matplotlib.pyplot as plt\n",
    "from a_star import a_star\n",
    "from utils import plot_path\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pi = math.pi\n",
    "def PointsInCircum(r,n=360, center = (0,0)):\n",
    "    return np.array([(center[0] + math.cos(2*pi/n*x)*r, center[1] + math.sin(2*pi/n*x)*r) for x in range(0,n+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_shapely_map(map_size, obstacles):\n",
    "    '''\n",
    "    Given map_size and list of obstacles where\n",
    "    an obstacle is described by a tuple (xmin, ymin, xmax, ymax),\n",
    "    create a shapely map. \n",
    "    '''\n",
    "    \n",
    "    pols = [box(0,0,map_size[0], map_size[1])]\n",
    "    for obstacle in obstacles:\n",
    "        pols.append(box(*obstacle))\n",
    "    lines = []\n",
    "    for pol in pols:\n",
    "        boundary = pol.boundary\n",
    "        if boundary.type == 'MultiLineString':\n",
    "            for line in boundary:\n",
    "                lines.append(line)\n",
    "        else:\n",
    "            lines.append(boundary)\n",
    "\n",
    "    MAP = MultiLineString(lines)\n",
    "    return MAP\n",
    "\n",
    "def get_map_arr(MAP_params, shape):\n",
    "    '''\n",
    "    Convert the shapely obstacles into a numpy grid\n",
    "    for use with the A* planner. \n",
    "    \n",
    "    MAP_params is of the form [(xmin, ymin, xmax, ymax), (xmin, ymin, xmax, ymax), ...]\n",
    "    describing each rectangular obstacle in the map. Currently only supports rectangles. \n",
    "    \n",
    "    Shape is just a tuple with the map size. \n",
    "    \n",
    "    '''\n",
    "    map_np = np.zeros(shape)\n",
    "    for param in MAP_params:\n",
    "        xmin, ymin, xmax, ymax = param\n",
    "        map_np[ymin:ymax, xmin:xmax] = 1\n",
    "        \n",
    "    return map_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def synthetic_sensor(MAP, robot_location):\n",
    "    '''\n",
    "    Given a shapely map and the robots current location, \n",
    "    return the 360 degree laser scanner. \n",
    "    '''\n",
    "    lines = []\n",
    "    # 100 is arbitrary radius. Just needs to be big enough to draw line across map. \n",
    "    points = PointsInCircum(100, center = robot_location)\n",
    "    # Create line to all points on circle\n",
    "    for point in points:\n",
    "        A = Point(robot_location)\n",
    "        B = Point(point)\n",
    "        line = LineString([A,B])\n",
    "        lines.append(line)\n",
    "        \n",
    "    # Get points of intersection. \n",
    "    for i, line in enumerate(lines):\n",
    "        # These two types of objects signify multiple intersections. \n",
    "        if type(MAP.intersection(line)) == shapely.geometry.multilinestring.MultiLineString or \\\n",
    "               type(MAP.intersection(line)) == shapely.geometry.multipoint.MultiPoint:\n",
    "            # Get the closest point\n",
    "            temp_dist = []\n",
    "            for point in MAP.intersection(line):\n",
    "#                 try:\n",
    "                temp_dist.append(LineString([robot_location, point]).length)\n",
    "            inter = MAP.intersection(line)[np.argmin(temp_dist)]\n",
    "        # This signifies no intersection. Wont happen on current map. \n",
    "        elif type(MAP.intersection(line)) == shapely.geometry.collection.GeometryCollection:\n",
    "            continue \n",
    "        # One intersection\n",
    "        else:\n",
    "            inter = MAP.intersection(line)\n",
    "        # Create new point and update end point in list of lines. \n",
    "        new_point = (inter.xy[0][0], inter.xy[1][0])\n",
    "        lines[i].coords = [robot_location, new_point]\n",
    "    \n",
    "    # Get lase scan data (distances)\n",
    "    distances = [line.length for line in lines]\n",
    "    return distances[:360]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot(MAP, robot_location, line_strings = None, plot_lines=False):\n",
    "    '''\n",
    "    This plot function is used to show the laser scan lines. \n",
    "    Current not used. Probably will be helpful when creating visualizations. \n",
    "    '''\n",
    "    fig = plt.figure(frameon=False)\n",
    "    fig.set_size_inches(50,50)\n",
    "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "    ax.set_axis_off()\n",
    "    fig.add_axes(ax)\n",
    "    for index, l in enumerate(MAP): \n",
    "        if index != 0:\n",
    "            ax.fill(*l.xy, alpha=1)\n",
    "        else:\n",
    "            ax.plot(*l.xy, alpha=1)\n",
    "    if plot_lines:\n",
    "        for line in line_strings:\n",
    "            ax.plot(*line.xy, alpha=0.25)\n",
    "    ax.scatter(*robot_location, s=30, alpha=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_path(start, goal, arr, plot = True):\n",
    "    '''\n",
    "    Given start (x,y) and goal (x,y) use numpy grid arr\n",
    "    to solve for best path with A*. \n",
    "    \n",
    "    By default, plot the A* path everytime this is called. \n",
    "    '''\n",
    "    resolution = 1\n",
    "    gmap = OccupancyGridMap(arr, resolution)\n",
    "\n",
    "    # 4n = 4 point connectivity. 8N = 8 point connectivity\n",
    "    path, path_px = a_star(start, goal, gmap, movement='4N')\n",
    "    if plot:\n",
    "        gmap.plot()\n",
    "        plot_path(path_px)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_path_(MAP, robot_location, goal_location, path):\n",
    "    '''\n",
    "    Plot path on map using shapely. Not currently used. \n",
    "    '''\n",
    "    fig = plt.figure(frameon=False)\n",
    "    fig.set_size_inches(6,6)\n",
    "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "    fig.add_axes(ax)\n",
    "    \n",
    "    for index, l in enumerate(MAP): \n",
    "        if index != 0:\n",
    "            ax.fill(*l.xy, alpha=1)\n",
    "        else:\n",
    "            ax.plot(*l.xy, alpha=1)\n",
    "    \n",
    "    ax.plot(*LineString(path).xy)\n",
    "    ax.scatter(robot_location[0], robot_location[1], s=30, alpha=1.0) \n",
    "    ax.scatter(goal_location[0], goal_location[1], s=30, alpha=1.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesize_data(start, goal, MAP, map_arr):\n",
    "    '''\n",
    "    synthesize data for one step. \n",
    "    \n",
    "    -Given start and goal, we first get the A* ground truth path. \n",
    "    -If get_path() returns an error, that means there was no path found. \n",
    "    -For each element in the path, use the synthetic sensor to get the readings \n",
    "        the relative goal in odom, and the target movement\n",
    "    '''\n",
    "    \n",
    "    # Get path if one is available\n",
    "    try:\n",
    "        path = get_path(start, goal, map_arr, False)\n",
    "    except:\n",
    "        return\n",
    "    \n",
    "    sensor_readings = []\n",
    "    relative_goals = []\n",
    "    directions = []\n",
    "    prev = start\n",
    "    for i, loc in enumerate(path):\n",
    "        # Get laser scan\n",
    "        sensor_readings.append(synthetic_sensor(MAP, loc))\n",
    "        # Get goal in odom\n",
    "        relative_goals.append((goal[0]-loc[0], goal[1]-loc[1]))\n",
    "        # Get movement to next cell\n",
    "        directions.append((loc[0] - prev[0], loc[1] - prev[1]))\n",
    "        prev=loc\n",
    "    return np.array(sensor_readings), np.array(relative_goals), directions, path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def synthesize_train_set(MAPs, num_runs = 500):\n",
    "    '''\n",
    "    -Get 'num_runs' different start/goal locations inside the map\n",
    "    -If path is available, get training data for a given path\n",
    "    -Return pandas dataframe where first 360 columns are sensor data, cols\n",
    "     361 and 362 are odom info and then last 2 columns are x,y movement directions. \n",
    "    '''\n",
    "    \n",
    "    df = []\n",
    "    \n",
    "    for i in tqdm(range(num_runs)):\n",
    "        # TODO: Generalize to any map shape\n",
    "        start = (random.randint(1,49), random.randint(1,49))\n",
    "        goal = (random.randint(1,49), random.randint(1,49))\n",
    "        MAP, map_arr = random.choice(MAPs)\n",
    "        # If path is available, get training info\n",
    "        try:\n",
    "            (sensor_readings, relative_goals, directions, path) = synthesize_data(start, goal, MAP, map_arr)\n",
    "            train = np.concatenate((sensor_readings, relative_goals, directions), axis=1)\n",
    "            df.append(train)\n",
    "        except:\n",
    "            # No path found\n",
    "            continue\n",
    "    return pd.DataFrame(np.vstack(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tuple(x):\n",
    "    '''\n",
    "    Function used to turn 2 pandas columns into\n",
    "    a tuple in one column. See create_classification_problem\n",
    "    for use. \n",
    "    '''\n",
    "    return (x.iloc[0], x.iloc[1])\n",
    "\n",
    "def create_classification_problem(df, one_hot = False):\n",
    "    '''\n",
    "    Now that training data has been synthesized, \n",
    "    prepare data for use with ML model. \n",
    "    '''\n",
    "    \n",
    "    # Turn (x,y) target into into string tuple\n",
    "    # so we can then use label encoding to turn\n",
    "    # this into a classification problem. \n",
    "    df['out'] = df[[362,363]].apply(make_tuple, axis=1)\n",
    "    df['out'] = df['out'].astype(str)\n",
    "    \n",
    "    # Drop the sample where we are at the target location. \n",
    "    # We don't want to learn to stay still. \n",
    "    df = df[df['out']!='(0.0, 0.0)']\n",
    " \n",
    "    # Label encode targets\n",
    "    enc = preprocessing.LabelEncoder()\n",
    "    df['out'] = enc.fit_transform(df['out'])\n",
    "    \n",
    "    # Added one-hot encoding option which\n",
    "    # may be neccessary for some models\n",
    "    if one_hot:\n",
    "        ohe = preprocessing.OneHotEncoder(sparse=False)\n",
    "        ohe.fit(df['out'].values.reshape(-1,1)) \n",
    "        df['out'] = df['out'].apply(lambda x : ohe.transform(x))\n",
    "        df['out'] = df['out'].apply(lambda x : x[0])\n",
    "    \n",
    "    # Drop the (x,y) target columns, which have now\n",
    "    # been label encoded. \n",
    "    df.drop([362, 363], axis=1, inplace=True)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d7145a1be0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d71356f6d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Map obstacles for training map. \n",
    "map_params = [(10, 10, 12, 16), (35,35,48,37), (0,5,8,8), (20,20,25,25), (40,11,49,4), (2,45,14,48), (44,0,49,20)]\n",
    "map_size = (50,50)\n",
    "# Gen training map\n",
    "train_MAP1 = gen_shapely_map(map_size, map_params)\n",
    "# Convert to numpy array for A*\n",
    "arr1 = get_map_arr(map_params, map_size)\n",
    "plt.imshow(arr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d7145d56a0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhi81ZPhSQ4YvNfR/3rwsksb1CngAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d7134be630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Map obstacles for training map. \n",
    "map_params = [(1,1,10,10),(10,15,20,20), (40,40,45,45),(30,30,40,40), (0,40,15,41)]\n",
    "map_size = (50,50)\n",
    "# Gen training map\n",
    "train_MAP2 = gen_shapely_map(map_size, map_params)\n",
    "# Convert to numpy array for A*\n",
    "arr2 = get_map_arr(map_params, map_size)\n",
    "plt.imshow(arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d714609e10>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSw39H+z6J0LCBdUgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d7145cd4a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Map obstacles for training map. \n",
    "map_params = [(10,5,13,20),(40,0,42,20), (1,49,22,50), (30,30,40,40), (20,20,30,30)]\n",
    "map_size = (50,50)\n",
    "# Gen training map\n",
    "train_MAP3 = gen_shapely_map(map_size, map_params)\n",
    "# Convert to numpy array for A*\n",
    "arr3 = get_map_arr(map_params, map_size)\n",
    "plt.imshow(arr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAPS = [(train_MAP1, arr1), (train_MAP2,arr2), (train_MAP3, arr3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 500/500 [1:22:46<00:00,  9.93s/it]\n"
     ]
    }
   ],
   "source": [
    "# # Create training data\n",
    "df_ = synthesize_train_set(MAPS)\n",
    "# Prep data for modeling\n",
    "df = create_classification_problem(df_.copy()) \n",
    "# Shuffle data (otherwise model can cheat and memorize order since these are no iid)\n",
    "df = df.sample(frac=1)\n",
    "# df = pd.read_csv('1k_runs.csv')\n",
    "# df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "# df.to_csv('1k_runs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('500_run_multimap.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.84454913 0.84855284 0.84219978]\n"
     ]
    }
   ],
   "source": [
    "# Get training acc\n",
    "from sklearn.svm import LinearSVC\n",
    "print(cross_val_score(RandomForestClassifier(n_estimators=100, max_depth=36), df.drop(['out'], axis=1).values, df['out'].values, cv=3, scoring = 'accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=36, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model using all data.\n",
    "clf = RandomForestClassifier(n_estimators=150, max_depth=36)\n",
    "clf.fit(df.drop(['out'], axis=1).values, df['out'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "'''\n",
    "Testing Env:\n",
    "\n",
    "Now we use trained model to nav unseen map. \n",
    "'''\n",
    "\n",
    "# Mapping from label encoder (just hard coded it here)\n",
    "dirs = {0:(-1.0, 0.0), 1:(0.0, -1.0), 2:(0.0, 1.0), 3:(1.0, 0.0)}\n",
    "# Create new map with different obstacles\n",
    "# map_params = [(20, 20, 22, 29), (30,40,40,49), (2,5,8,8), (0,25,5,29)]\n",
    "# test_MAP = gen_shapely_map((50,50), map_params)\n",
    "# arr = get_map_arr(map_params, (50,50))\n",
    "\n",
    "map_params = [(10, 10, 12, 16), (35,35,48,37), (0,5,8,8), (20,20,25,25), (40,11,49,4), (2,45,14,48), (44,0,49,20)]\n",
    "map_size = (50,50)\n",
    "# Gen training map\n",
    "test_MAP = gen_shapely_map(map_size, map_params)\n",
    "# Convert to numpy array for A*\n",
    "arr = get_map_arr(map_params, map_size)\n",
    "\n",
    "def test_on_new_map(_MAP, test_arr, start, goal, model):\n",
    "    \n",
    "    '''\n",
    "    Test model performance on unseen map. \n",
    "    \n",
    "    test_MAP = shapely map\n",
    "    test_arr = numpy grid of mapll\n",
    "    \n",
    "    start,goal = (x,y), (x,y)\n",
    "    model = trained sklearn model \n",
    "    '''\n",
    "    \n",
    "    # Get ground-truth path\n",
    "    groud_truth = get_path(start, goal, test_arr) \n",
    "    print(\"Number of steps taken in A* Path, \", len(groud_truth))\n",
    "    \n",
    "    # i counter just helps stop after a certain number of steps since\n",
    "    # at the moment the algorithm probably wont reach the goal. \n",
    "    i=0\n",
    "    # Start saving the path traveled\n",
    "    pred_path = [start]\n",
    "    \n",
    "    cur = start\n",
    "    while cur != goal:\n",
    "        try:\n",
    "            # Get the laser_scan data for the current point\n",
    "            laser_scan = synthetic_sensor(_MAP, cur)\n",
    "    #         print(len(laser_scan))\n",
    "    #         print(i, laser_scan)\n",
    "            # Add the odom frame goal to the array\n",
    "            laser_scan.append(goal[0]-cur[0])\n",
    "            laser_scan.append(goal[1]-cur[1])\n",
    "            # Create model input\n",
    "            inpX = np.array(laser_scan)\n",
    "            # Get predicted direction\n",
    "            inds = clf.predict_proba(inpX.reshape(1,-1))[0]\n",
    "            best = list(np.argsort(inds))\n",
    "            best.reverse()\n",
    "\n",
    "            possible_next_states = [(cur[0] + dirs[ind][0], cur[1] + dirs[ind][1]) for ind in best]\n",
    "            temp_states = deepcopy(possible_next_states)\n",
    "            for state in possible_next_states:\n",
    "                if (-1 in state) or (50 in state) or (0 in state) or (state in pred_path):\n",
    "                    temp_states.remove(state)\n",
    "\n",
    "\n",
    "            # Update state\n",
    "            cur = temp_states[0]\n",
    "#             print(cur)\n",
    "            assert cur not in pred_path\n",
    "            pred_path.append(cur)\n",
    "            # Cout number of steps traveled \n",
    "            i+=1\n",
    "            if i==60 or cur == goal:\n",
    "                break\n",
    "        except:\n",
    "            break\n",
    "    \n",
    "    return pred_path \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A* Path\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d714627b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of steps taken in A* Path,  59\n"
     ]
    }
   ],
   "source": [
    "print(\"A* Path\")\n",
    "#4,2 49,40\n",
    "pred_path = test_on_new_map(test_MAP, arr, (1,1), (30,30), clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d713403a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "OccupancyGridMap(arr, 1).plot()\n",
    "plot_path(pred_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
