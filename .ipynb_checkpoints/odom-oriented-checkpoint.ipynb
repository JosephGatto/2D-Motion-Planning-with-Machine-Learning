{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import shapely\n",
    "from shapely.geometry import box, MultiPolygon, LineString, Point, MultiLineString, Polygon\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "from gridmap import OccupancyGridMap\n",
    "import matplotlib.pyplot as plt\n",
    "from a_star import a_star\n",
    "from utils import plot_path\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import imageio\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points_on_circ = 4\n",
    "pi = math.pi\n",
    "def PointsInCircum(r,n=num_points_on_circ, center = (0,0)):\n",
    "    return np.array([(center[0] + math.cos(2*pi/n*x)*r, center[1] + math.sin(2*pi/n*x)*r) for x in range(0,n+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_shapely_map(map_size, obstacles):\n",
    "    '''\n",
    "    Given map_size and list of obstacles where\n",
    "    an obstacle is described by a tuple (xmin, ymin, xmax, ymax),\n",
    "    create a shapely map. \n",
    "    '''\n",
    "    \n",
    "    pols = [box(0,0,map_size[0], map_size[1])]\n",
    "    for obstacle in obstacles:\n",
    "        pols.append(box(*obstacle))\n",
    "    lines = []\n",
    "    for pol in pols:\n",
    "        boundary = pol.boundary\n",
    "        if boundary.type == 'MultiLineString':\n",
    "            for line in boundary:\n",
    "                lines.append(line)\n",
    "        else:\n",
    "            lines.append(boundary)\n",
    "\n",
    "    MAP = MultiLineString(lines)\n",
    "    return MAP\n",
    "\n",
    "def get_map_arr(MAP_params, shape):\n",
    "    '''\n",
    "    Convert the shapely obstacles into a numpy grid\n",
    "    for use with the A* planner. \n",
    "    \n",
    "    MAP_params is of the form [(xmin, ymin, xmax, ymax), (xmin, ymin, xmax, ymax), ...]\n",
    "    describing each rectangular obstacle in the map. Currently only supports rectangles. \n",
    "    \n",
    "    Shape is just a tuple with the map size. \n",
    "    \n",
    "    '''\n",
    "    map_np = np.zeros(shape)\n",
    "    for param in MAP_params:\n",
    "        xmin, ymin, xmax, ymax = param\n",
    "        map_np[ymin:ymax, xmin:xmax] = 1\n",
    "        \n",
    "    return map_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping from label encoder (just hard coded it here)\n",
    "dirs = {0:(1.0, 0.0), 1:(0.0, 1.0), 2:(-1.0, 0.0), 3:(0.0, -1.0)}\n",
    "inv_dirs = {d: label for label, d in dirs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4n = 4 point connectivity. 8N = 8 point connectivity\n",
    "def synthetic_sensor(MAP, robot_location, direction, movement='4N'):\n",
    "    '''\n",
    "    Given a shapely map and the robots current location, \n",
    "    return the 360 degree laser scanner. \n",
    "    '''\n",
    "    lines = []\n",
    "    # 100 is arbitrary radius. Just needs to be big enough to draw line across map. \n",
    "    points = PointsInCircum(100, center = robot_location)\n",
    "    # Create line to all points on circle\n",
    "    for point in points:\n",
    "        A = Point(robot_location)\n",
    "        B = Point(point)\n",
    "        line = LineString([A,B])\n",
    "        lines.append(line)\n",
    "    # Get points of intersection. \n",
    "    for i, line in enumerate(lines):\n",
    "\n",
    "        # These two types of objects signify multiple intersections. \n",
    "        if type(MAP.intersection(line)) == shapely.geometry.multilinestring.MultiLineString or \\\n",
    "               type(MAP.intersection(line)) == shapely.geometry.multipoint.MultiPoint:\n",
    "            # Get the closest point\n",
    "            temp_dist = []\n",
    "            for point in MAP.intersection(line):\n",
    "#                 try:\n",
    "                temp_dist.append(LineString([robot_location, point]).length)\n",
    "            inter = MAP.intersection(line)[np.argmin(temp_dist)]\n",
    "        # This signifies no intersection. Wont happen on current map. \n",
    "        elif type(MAP.intersection(line)) == shapely.geometry.collection.GeometryCollection:\n",
    "            cp = MAP.intersection(line)[0] \n",
    "            lines[i].coords = [robot_location, cp]\n",
    "            continue\n",
    "        # One intersection\n",
    "        else:\n",
    "            inter = MAP.intersection(line)\n",
    "        # Create new point and update end point in list of lines. \n",
    "        new_point = (inter.xy[0][0], inter.xy[1][0])\n",
    "        lines[i].coords = [robot_location, new_point]\n",
    "    \n",
    "    # Get lase scan data (distances)\n",
    "    distances = [line.length for line in lines][:num_points_on_circ]\n",
    "    # Account for robot orientation\n",
    "    if direction != (0, 0): # Start node\n",
    "        if movement == '4N':\n",
    "            offset = int(len(distances) / 4.) * inv_dirs[direction]\n",
    "        else: \n",
    "            offset = int(len(distances) / 8.) * inv_dirs[direction]\n",
    "        distances = distances[offset:] + distances[:offset]  \n",
    "    return distances, lines\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(MAP, robot_location, line_strings = None, plot_lines=False):\n",
    "    '''\n",
    "    This plot function is used to show the laser scan lines. \n",
    "    Current not used. Probably will be helpful when creating visualizations. \n",
    "    '''\n",
    "    fig = plt.figure(frameon=False)\n",
    "    fig.set_size_inches(50,50)\n",
    "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "    ax.set_axis_off()\n",
    "    fig.add_axes(ax)\n",
    "    for index, l in enumerate(MAP): \n",
    "        if index != 0:\n",
    "            ax.fill(*l.xy, alpha=1)\n",
    "        else:\n",
    "            ax.plot(*l.xy, alpha=1)\n",
    "    if plot_lines:\n",
    "        for line in line_strings:\n",
    "            ax.plot(*line.xy, alpha=0.25)\n",
    "    ax.scatter(*robot_location, s=30, alpha=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path(start, goal, arr, plot = True):\n",
    "    '''\n",
    "    Given start (x,y) and goal (x,y) use numpy grid arr\n",
    "    to solve for best path with A*. \n",
    "    \n",
    "    By default, plot the A* path everytime this is called. \n",
    "    '''\n",
    "    resolution = 1\n",
    "    gmap = OccupancyGridMap(arr, resolution)\n",
    "\n",
    "    # 4n = 4 point connectivity. 8N = 8 point connectivity\n",
    "    path, path_px = a_star(start, goal, gmap, movement='4N')\n",
    "    if plot:\n",
    "        gmap.plot()\n",
    "        plot_path(path_px)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_path_(MAP, robot_location, goal_location, path):\n",
    "    '''\n",
    "    Plot path on map using shapely. Not currently used. \n",
    "    '''\n",
    "    fig = plt.figure(frameon=False)\n",
    "    fig.set_size_inches(6,6)\n",
    "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "    fig.add_axes(ax)\n",
    "    \n",
    "    for index, l in enumerate(MAP): \n",
    "        if index != 0:\n",
    "            ax.fill(*l.xy, alpha=1)\n",
    "        else:\n",
    "            ax.plot(*l.xy, alpha=1)\n",
    "    \n",
    "    ax.plot(*LineString(path).xy)\n",
    "    ax.scatter(robot_location[0], robot_location[1], s=30, alpha=1.0) \n",
    "    ax.scatter(goal_location[0], goal_location[1], s=30, alpha=1.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesize_data(start, goal, MAP, map_arr, polar=False):\n",
    "    '''\n",
    "    synthesize data for one step. \n",
    "    \n",
    "    -Given start and goal, we first get the A* ground truth path. \n",
    "    -If get_path() returns an error, that means there was no path found. \n",
    "    -For each element in the path, use the synthetic sensor to get the readings \n",
    "        the relative goal in odom, and the target movement\n",
    "    '''\n",
    "    \n",
    "    # Get path if one is available\n",
    "    try:\n",
    "        path = get_path(start, goal, map_arr, False)\n",
    "    except:\n",
    "        return\n",
    "    \n",
    "    sensor_readings = []\n",
    "    relative_goals = []\n",
    "    polar_goals = [] # Polar coordinates used by paper\n",
    "    directions = []\n",
    "    prev = start\n",
    "    for i, loc in enumerate(path):\n",
    "        # Get direction to next cell\n",
    "        direction = (loc[0] - prev[0], loc[1] - prev[1])\n",
    "        # Get rotation\n",
    "        offset = 0\n",
    "        if direction != (0, 0): # Start node\n",
    "            offset = inv_dirs[direction]\n",
    "        rot = np.pi/2 * offset\n",
    "        # Get laser scan\n",
    "        ls,_ = synthetic_sensor(MAP, (loc[0]+0.5, loc[1]+0.5), direction)\n",
    "        sensor_readings.append(ls)\n",
    "        # Get goal in odom\n",
    "        goal_loc = (goal[0]-loc[0], goal[1]-loc[1])  \n",
    "        # Get goal in odom\n",
    "        goal_orn = (goal_loc[0]*np.cos(rot) + goal_loc[1]*np.sin(rot), goal_loc[0]*-np.sin(rot) + goal_loc[1]*np.cos(rot))\n",
    "        relative_goals.append(goal_orn)   \n",
    "#         relative_goals.append(goal_loc)\n",
    "        \n",
    "        # Get polar distance\n",
    "        polar_distance = np.linalg.norm(np.array([goal_loc[0],goal_loc[1]]))\n",
    "        # Get polar rotation\n",
    "        polar_rotation = math.atan2(goal_loc[1], goal_loc[0]) + rot\n",
    "        polar_goals.append((polar_distance, polar_rotation))\n",
    "        \n",
    "        # Get movement to next cell\n",
    "        directions.append(direction)\n",
    "        prev=loc\n",
    "    \n",
    "    # Return polar goals if True\n",
    "    if polar:\n",
    "        return np.array(sensor_readings), np.array(polar_goals), directions, path\n",
    "    return np.array(sensor_readings), np.array(relative_goals), directions, path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesize_train_set(MAPs, num_runs = 5):\n",
    "    '''\n",
    "    -Get 'num_runs' different start/goal locations inside the map\n",
    "    -If path is available, get training data for a given path\n",
    "    -Return pandas dataframe where first 360 columns are sensor data, cols\n",
    "     361 and 362 are odom info and then last 2 columns are x,y movement directions. \n",
    "    '''\n",
    "    \n",
    "    df = []\n",
    "    \n",
    "    for i in tqdm(range(num_runs)):\n",
    "        # TODO: Generalize to any map shape\n",
    "        start = (random.randint(1,49), random.randint(1,49))\n",
    "        goal = (random.randint(1,49), random.randint(1,49))\n",
    "        MAP, map_arr = random.choice(MAPs)\n",
    "        # If path is available, get training info\n",
    "        try:\n",
    "            (sensor_readings, relative_goals, directions, path) = synthesize_data(start, goal, MAP, map_arr)\n",
    "            train = np.concatenate((sensor_readings, relative_goals, directions), axis=1)\n",
    "            df.append(train)\n",
    "        except:\n",
    "            # No path found\n",
    "            continue\n",
    "    return pd.DataFrame(np.vstack(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tuple(x):\n",
    "    '''\n",
    "    Function used to turn 2 pandas columns into\n",
    "    a tuple in one column. See create_classification_problem\n",
    "    for use. \n",
    "    '''\n",
    "    return (x.iloc[0], x.iloc[1])\n",
    "\n",
    "def get_inv_dirs(x):\n",
    "    '''\n",
    "    Function to encode direction tuple according to hard-coded encoding\n",
    "    '''\n",
    "    return inv_dirs[x]\n",
    "\n",
    "def create_classification_problem(df, one_hot = False):\n",
    "    '''\n",
    "    Now that training data has been synthesized, \n",
    "    prepare data for use with ML model. \n",
    "    '''\n",
    "    \n",
    "    # Turn (x,y) target into into string tuple\n",
    "    # so we can then use label encoding to turn\n",
    "    # this into a classification problem. \n",
    "    df['out'] = df[[num_points_on_circ+2,num_points_on_circ+3]].apply(make_tuple, axis=1)\n",
    "#     df['out'] = df['out'].astype(str)\n",
    "    \n",
    "    # Drop the sample where we are at the target location. \n",
    "    # We don't want to learn to stay still. \n",
    "#     df = df[df['out']!='(0.0, 0.0)']\n",
    "    df = df[df['out']!=(0.0, 0.0)]\n",
    " \n",
    "    # Label encode targets\n",
    "#     enc = preprocessing.LabelEncoder()\n",
    "#     df['out'] = enc.fit_transform(df['out'])\n",
    "    df['out'] = df['out'].apply(get_inv_dirs)\n",
    "    \n",
    "    # Added one-hot encoding option which\n",
    "    # may be neccessary for some models\n",
    "    if one_hot:\n",
    "        ohe = preprocessing.OneHotEncoder(sparse=False)\n",
    "        ohe.fit(df['out'].values.reshape(-1,1)) \n",
    "        df['out'] = df['out'].apply(lambda x : ohe.transform(x))\n",
    "        df['out'] = df['out'].apply(lambda x : x[0])\n",
    "    \n",
    "    # Drop the (x,y) target columns, which have now\n",
    "    # been label encoded. \n",
    "    df.drop([num_points_on_circ+2, num_points_on_circ+3], axis=1, inplace=True)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadFits(map_np, sx, sy, rx, ry, margin):\n",
    "        \"\"\"\n",
    "        looks to see if a quad shape will fit in the grid without colliding with any other tiles\n",
    "        used by placeRoom() and placeRandomRooms()\n",
    "         \n",
    "        Args:\n",
    "            sx and sy: integer, the bottom left coords of the quad to check\n",
    "            rx and ry: integer, the width and height of the quad, where rx > sx and ry > sy\n",
    "            margin: integer, the space in grid cells (ie, 0 = no cells, 1 = 1 cell, 2 = 2 cells) to be away from other tiles on the grid\n",
    "             \n",
    "        returns:\n",
    "            True if the quad fits\n",
    "        \"\"\"\n",
    "         \n",
    "        sx -= margin\n",
    "        sy -= margin\n",
    "        rx += margin*2\n",
    "        ry += margin*2\n",
    "        if sx + rx < np.size(map_np, axis=1) and sy + ry < np.size(map_np, axis=0) and sx >= 0 and sy >= 0:\n",
    "            for x in range(rx):\n",
    "                for y in range(ry):\n",
    "                    if map_np[sy+y, sx+x]: \n",
    "                        return False\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "def placeRandomRooms(map_size, minRoomSize, maxRoomSize, roomStep = 1, margin = 1, attempts = 500):\n",
    "    \"\"\" \n",
    "    randomly places quads in the grid\n",
    "    takes a brute force approach: randomly a generate quad in a random place -> check if fits -> reject if not\n",
    "    Populates self.rooms\n",
    "\n",
    "    Args:\n",
    "        minRoomSize: integer, smallest size of the quad\n",
    "        maxRoomSize: integer, largest the quad can be\n",
    "        roomStep: integer, the amount the room size can grow by, so to get rooms of odd or even numbered sizes set roomSize to 2 and the minSize to odd/even number accordingly\n",
    "        margin: integer, space in grid cells the room needs to be away from other tiles\n",
    "        attempts: the amount of tries to place rooms, larger values will give denser room placements, but slower generation times\n",
    "\n",
    "    Returns:\n",
    "        none\n",
    "    \"\"\"\n",
    "    \n",
    "    pols = [box(0,0,map_size[0], map_size[1])]\n",
    "    map_np = np.zeros(map_size)\n",
    "    \n",
    "    for attempt in range(attempts):\n",
    "        roomWidth = random.randrange(minRoomSize, maxRoomSize, roomStep)\n",
    "        roomHeight = random.randrange(minRoomSize, maxRoomSize, roomStep)\n",
    "        startX = random.randint(0, map_size[1])\n",
    "        startY = random.randint(0, map_size[0])            \n",
    "        if quadFits(map_np, startX, startY, roomWidth, roomHeight, margin):\n",
    "            for x in range(roomWidth):\n",
    "                for y in range(roomHeight):\n",
    "                    map_np[startY+y, startX+x] = 1\n",
    "            pols.append(box(startX, startY, startX+roomWidth, startY+roomHeight))\n",
    "    \n",
    "    lines = []\n",
    "    for pol in pols:\n",
    "        boundary = pol.boundary\n",
    "        if boundary.type == 'MultiLineString':\n",
    "            for line in boundary:\n",
    "                lines.append(line)\n",
    "        else:\n",
    "            lines.append(boundary)\n",
    "\n",
    "    MAP = MultiLineString(lines)\n",
    "    return map_np, MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 14.08it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get trainning data\n",
    "map_size = (50,50)\n",
    "MAPS = []\n",
    "for i in range(20):\n",
    "    arr, train_MAP = placeRandomRooms(map_size, minRoomSize=3, maxRoomSize=15, roomStep = 1, margin = 1, attempts = 100)\n",
    "    MAPS.append((train_MAP,arr))\n",
    "\n",
    "df_ = synthesize_train_set(MAPS, num_runs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep data for modeling\n",
    "df = create_classification_problem(df_.copy()) \n",
    "# Shuffle data (otherwise model can cheat and memorize order since these are no iid)\n",
    "df = df.sample(frac=1)\n",
    "\n",
    "# df = pd.read_csv('500_multimap2.csv')\n",
    "# df.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95       0.94871795 1.        ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=36, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(cross_val_score(RandomForestClassifier(), df.drop(['out'], axis=1).values, df['out'].values, cv=3, scoring = 'f1_micro'))\n",
    "# Fit model using all data.\n",
    "clf = RandomForestClassifier(n_estimators=150, max_depth=36)\n",
    "# df.drop(0, axis=0, inplace=True)\n",
    "clf.fit(df.drop(['out'], axis=1).values, df['out'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "'''\n",
    "Testing Env:\n",
    "\n",
    "Now we use trained model to nav unseen map. \n",
    "'''\n",
    "\n",
    "# Mapping from label encoder (just hard coded it here)\n",
    "# dirs = {0:(-1.0, 0.0), 1:(0.0, -1.0), 2:(0.0, 1.0), 3:(1.0, 0.0)}\n",
    "dirs = {0:(1.0, 0.0), 1:(0.0, 1.0), 2:(-1.0, 0.0), 3:(0.0, -1.0)}\n",
    "\n",
    "map_params = [(5,8,18,23), (45,0,50,12), (10,10,15,15), (25,20,35,25), (44,44,49,49), (31,38,40,40), (30,10,39,19), (15,25,28,30), (30,30,35,35),(0,45,10,46), (20,30,5,35)]\n",
    "map_size = (50,50)\n",
    "# Gen training map\n",
    "test_MAP = gen_shapely_map(map_size, map_params)\n",
    "# Convert to numpy array for A*\n",
    "arr = get_map_arr(map_params, map_size)\n",
    "\n",
    "def test_on_new_map(_MAP, test_arr, start, goal, model):\n",
    "    \n",
    "    '''\n",
    "    Test model performance on unseen map. \n",
    "    \n",
    "    test_MAP = shapely map\n",
    "    test_arr = numpy grid of mapll\n",
    "    \n",
    "    start,goal = (x,y), (x,y)\n",
    "    model = trained sklearn model \n",
    "    '''\n",
    "    \n",
    "    # Get ground-truth path\n",
    "    groud_truth = get_path(start, goal, test_arr) \n",
    "    print(\"Number of steps taken in A* Path, \", len(groud_truth))\n",
    "    \n",
    "    # i counter just helps stop after a certain number of steps since\n",
    "    # at the moment the algorithm probably wont reach the goal. \n",
    "    i=0\n",
    "    # Start saving the path traveled\n",
    "    pred_path = [start]\n",
    "    cur_dir = (0, 0) # Get robot direction\n",
    "    cur = start\n",
    "    while cur != goal:\n",
    "        try:\n",
    "            # Get the laser_scan data for the current point\n",
    "#             cur = (cur[0]+1, cur[1]+1)\n",
    "            laser_scan, lines = synthetic_sensor(_MAP, (cur[0]+0.5, cur[1]+0.5), direction=cur_dir)\n",
    "            laser_scan.append(goal[0]-cur[0])\n",
    "            laser_scan.append(goal[1]-cur[1])\n",
    "            # Create model input\n",
    "            inpX = np.array(laser_scan)\n",
    "            print(inpX)\n",
    "            # Get predicted direction\n",
    "            inds = model.predict_proba(inpX.reshape(1,-1))[0]\n",
    "            best = list(np.argsort(inds))\n",
    "            best.reverse()\n",
    "            \n",
    "            possible_next_states = [(cur[0] + dirs[ind][0], cur[1] + dirs[ind][1]) for ind in best]\n",
    "            temp_states = deepcopy(possible_next_states)\n",
    "            for state in possible_next_states:\n",
    "                if (-1 in state) or (50 in state) or (0 in state) or (state in pred_path):\n",
    "                    temp_states.remove(state)\n",
    "\n",
    "            # Update state\n",
    "            cur_dir = (temp_states[0][0] - cur[0], temp_states[0][1] - cur[1])\n",
    "            cur = temp_states[0]\n",
    "            \n",
    "            assert cur not in pred_path\n",
    "            pred_path.append(cur)\n",
    "            # Cout number of steps traveled \n",
    "            i+=1\n",
    "            if i==100 or cur == goal:\n",
    "                break\n",
    "        except:\n",
    "            break\n",
    "    \n",
    "    return pred_path \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAANB0lEQVR4nO3df6xf9V3H8ed7/XX5IXSdpVZKBaQxzEYh3iARYxzdMgQ2SIZmY1tq0qT+oQkLixvTxGTGP9g/MP8warOSVTMHG1sCAoaQrg1ZYmC3lM3WRgtEK6NSDD82rC20ffvHPYXS3tv7vd/v+f667+cjubnfc77n2++rzX31c87nnvM9kZlIWvjeN+wAkgbDsktFWHapCMsuFWHZpSIWD/LNlsaynOC8Qb6lVMoR/pe38mjM9NxAyz7Befx6bBjkW0qlPJXbZ33O3XipCMsuFWHZpSIsu1SEZZeKsOxSEZZdKsKyS0VYdqkIyy4VYdmlIgZ6bvwoe/ylZ4cdYeA++vNXDTuCBsiRXSrCsktFWHapCMsuFWHZpSIsu1SEZZeKsOxSEZZdKsKyS0VYdqkIyy4VYdmlIiy7VIRll4qw7FIRll0qwrJLRVh2qQjLLhVh2aUiLLtUhGWXirDsUhGWXSqi4zvCRMQiYAr4cWbeHBGXAfcDK4BngM9m5lv9ifmutu7c4t1QVM18RvY7gH2nLH8FuDcz1wGvAZvaDCapXR2VPSLWADcBX2uWA7geeLDZZBtwaz8CSmpHpyP7V4EvACea5Q8Ar2fmsWb5ReDimV4YEZsjYioipt7maE9hJXVvzrJHxM3AoczcderqGTbNmV6fmVsyczIzJ5ewrMuYknrVyQTddcDHI+JGYAK4gOmRfnlELG5G9zXAS/2LKQ1PN5PCozgBPOfInplfysw1mXkp8Enge5n5aWAHcFuz2Ubgob6llNSzXn7P/kXgzoh4julj+K3tRJLUDx3/nh0gM3cCO5vHLwDXtB9JUj94Bp1UhGWXirDsUhGWXSrCsktFWHapCMsuFWHZpSIsu1TEvM6gGwX9usBgFC9ckNrkyC4VYdmlIiy7VMTYHbP3S1ufWjvKnJfozkL5d3Nkl4qw7FIRll0qwrJLRVh2qQjLLhVh2aUiLLtUxFBPqvH2y9LgOLJLRVh2qQjLLhVh2aUiLLtUhGWXirDsUhF+eIUWtDbO5Vgo53E4sktFWHapCMsuFTFn2SNiIiKejogfRsTeiPhys/6yiHgqIvZHxAMRsbT/cSV1q5MJuqPA9Zn5ZkQsAb4fEf8E3Ancm5n3R8TfAJuAv57Pmy+UiQ+pE91MFrbZkTlH9pz2ZrO4pPlK4HrgwWb9NuDW1lJJal1Hx+wRsSgingUOAU8AzwOvZ+axZpMXgYtnee3miJiKiKm3OdpGZkld6KjsmXk8M68C1gDXAFfOtNksr92SmZOZObmEZd0nldSTec3GZ+brwE7gWmB5RJw85l8DvNRuNElt6mQ2fmVELG8enwN8GNgH7ABuazbbCDzUr5CSetfJbPxqYFtELGL6P4dvZeYjEfGvwP0R8RfAbmBrH3NK6tGcZc/MHwFXz7D+BaaP3yWNAS+E0VkdXH+A5zfs4ciFh5l441x+cft6Vu9ZO+xY6oJlb3iCz5kOrj/Avo/t4sTS4wAcWX6YfR/bBWDhx5DnxmtWz2/Y807RTzqx9Dj/fdsUV9/0wpBSqVuWXbM6cuHhGde/mif45Q0HBpxGvbLsmtXEG+fOuH5F+GMzjjxmL2S+F2L8w/7z+YMn/4/Dx949OfJ9by3iExee03a0vnEu5l3+F61Z3b7uAv72t1ay9vzFBLD2/MVc+Y+/xm8snRh2NHXBkV1ndfu6C7h93QXvLH/0j9cCTs6NI0d2qQhHdmlAhj1/4MguFWHZpSIsu1SEZZeKWBATdG3c4meUDHsiRwuTI7tUhGWXirDsUhEL4phdNS20uZpO9DKf48guFWHZpSIsu1SEZZeKsOxSEZZdKsKyS0VYdqkIyy4VYdmlIiy7VIRll4qw7FIRXvWmrqy64g0+c8/Onv6MvdvXsvvRy9sJpDk5smve9m5fy8vPXdjTn7Hqije8E+yAzTmyR8QlwN8BPwecALZk5l9GxArgAeBS4D+A38vM1/oXVaNi96OX9zwi97pXoPnrZDf+GPD5zHwmIn4G2BURTwC/D2zPzLsj4i7gLuCL/YuqUdXNh0j8/f19CKKzmnM3PjMPZuYzzeOfAvuAi4FbgG3NZtuAW/sVUlLv5nXMHhGXAlcDTwGrMvMgTP+HAFzUdjhJ7em47BFxPvAd4HOZ+ZN5vG5zRExFxNTbHO0mo6QWdFT2iFjCdNG/kZnfbVa/HBGrm+dXA4dmem1mbsnMycycXMKyNjJL6sKcZY+IALYC+zLznlOeehjY2DzeCDzUfjxJbelkNv464LPAv0TEyWnXPwHuBr4VEZuAA8Dv9ieipDbMWfbM/D4Qszy9od04kvrFM+ikIhbEufHe9VSamyO7VIRll4qw7FIRll0qYkFM0KkzTmTW5sguFWHZpSIsu1SEx+yNbj5tpRseN2tYHNmlIiy7VIRll4rwmF1jy/mP+bHsGpo27iozakb5Ljfuxmso2rirzKgZ9bvcOLJrKNq4q8yoGfW9FEd2qQhH9gWim5OCKk5w9evkqXH4t3Rkl4qw7FIRll0qwrJLRVh2qQjLLhVh2aUiLLtUhGWXirDsUhGWXSrCsktFWHapCMsuFWHZpSLmLHtE3BcRhyJizynrVkTEExGxv/n+/v7GlNSrTkb2rwM3nLbuLmB7Zq4DtjfLkkbYnGXPzCeBV09bfQuwrXm8Dbi15VySWtbtMfuqzDwI0Hy/aLYNI2JzRExFxNTbHO3y7ST1qu8TdJm5JTMnM3NyCcv6/XaSZtHtB06+HBGrM/NgRKwGDrUZahjG4QMDpV50O7I/DGxsHm8EHmonjqR+6eRXb98E/hn4pYh4MSI2AXcDH4mI/cBHmmVJI2zO3fjM/NQsT21oOYukPvIMOqkIyy4VYdmlIiy7VIRll4rwLq7qmSckjQdHdqkIyy4VYdmlIsoesz/+0rNDeV+Pb2v6UB5gE3tYyWFe4Vy2sp4dsXagGcqWXRqUD+UB7mQXExwHYBWHuZNdkAy08JZdatGqK97gM/fsfM+6T/z5q0y8duI96yY4zib2sAPLLo2dvdvXAgfOWH/eaUU/aSWH+5zovSy71JLdj17O7kcvP2P9DTzGqhmK/QrnDiLWO5yNl/psK+s5wqL3rDvCIrayfqA5HNmlPtsRayFxNl6qYEesHehk3EzcjZeKsOxSEZZdKsKyS0VYdqkIyy4VUfZXbwvt6rOF9vdR+xzZpSIsu1SEZZeKKHvMrpoqz204sktFWHapCMsuFWHZpSIsu1SEZZeK6KnsEXFDRPxbRDwXEXe1FUpS+7oue0QsAv4K+B3gg8CnIuKDbQWT1K5eRvZrgOcy84XMfAu4H7ilnViS2tZL2S8G/uuU5RebdZJGUC+ny8YM6/KMjSI2A5sBJgb8ofiS3tXLyP4icMkpy2uAl07fKDO3ZOZkZk4uYVkPbyepF5F5xmDc2QsjFgP/DmwAfgz8ALg9M/ee5TWvAP8J/CzwP1298eCNU1YYr7zjlBXGI+8vZObKmZ7oejc+M49FxB8BjwOLgPvOVvTmNSsBImIqMye7fe9BGqesMF55xykrjF/e0/V0iWtmPgY81lIWSX3kGXRSEcMq+5YhvW83xikrjFfeccoK45f3PbqeoJM0XtyNl4qw7FIRAy37qF8lFxH3RcShiNhzyroVEfFEROxvvr9/mBlPiohLImJHROyLiL0RcUezflTzTkTE0xHxwybvl5v1l0XEU03eByJi6bCznhQRiyJid0Q80iyPbNZODKzsY3KV3NeBG05bdxewPTPXAdub5VFwDPh8Zl4JXAv8YfPvOap5jwLXZ+avAlcBN0TEtcBXgHubvK8Bm4aY8XR3APtOWR7lrHMa5Mg+8lfJZeaTwKunrb4F2NY83gbcOtBQs8jMg5n5TPP4p0z/UF7M6ObNzHyzWVzSfCVwPfBgs35k8kbEGuAm4GvNcjCiWTs1yLKP61VyqzLzIEwXDLhoyHnOEBGXAlcDTzHCeZvd4meBQ8ATwPPA65l5rNlklH4mvgp8ATjRLH+A0c3akUGWvaOr5DQ/EXE+8B3gc5n5k2HnOZvMPJ6ZVzF90dQ1wJUzbTbYVGeKiJuBQ5m569TVM2w69KzzMcg7wnR0ldwIejkiVmfmwYhYzfSoNBIiYgnTRf9GZn63WT2yeU/KzNcjYifTcw3LI2JxM2KOys/EdcDHI+JGYAK4gOmRfhSzdmyQI/sPgHXNjOZS4JPAwwN8/249DGxsHm8EHhpilnc0x5BbgX2Zec8pT41q3pURsbx5fA7wYabnGXYAtzWbjUTezPxSZq7JzEuZ/jn9XmZ+mhHMOi+ZObAv4EamL4t9HvjTQb53h/m+CRwE3mZ6T2QT08dq24H9zfcVw87ZZP1NpncjfwQ823zdOMJ5fwXY3eTdA/xZs/5y4GngOeDbwLJhZz0t928Dj4xD1rm+PF1WKsIz6KQiLLtUhGWXirDsUhGWXSrCsktFWHapiP8H3UTUBdBekoMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of steps taken in A* Path,  42\n",
      "[  5.5   9.5   2.5   6.5 -19.   22. ]\n",
      "[  1.5   6.5   6.5   9.5 -18.   22. ]\n",
      "[  0.5   6.5   7.5   9.5 -17.   22. ]\n",
      "[  4.5   3.5   0.5   8.5 -16.   22. ]\n",
      "[  3.5   3.5   1.5   8.5 -15.   22. ]\n",
      "[  2.5   3.5   2.5   8.5 -14.   22. ]\n",
      "[  1.5   3.5   3.5   8.5 -13.   22. ]\n",
      "[  0.5   3.5   4.5   8.5 -12.   22. ]\n",
      "[ 13.5   6.5   0.5   9.5 -11.   22. ]\n",
      "[ 12.5   6.5   1.5   9.5 -10.   22. ]\n",
      "[11.5  6.5  2.5  9.5 -9.  22. ]\n",
      "[10.5  6.5  3.5 43.5 -8.  22. ]\n",
      "[ 9.5  6.5  4.5 43.5 -7.  22. ]\n",
      "[ 8.5  6.5  5.5 43.5 -6.  22. ]\n",
      "[ 7.5  6.5  6.5 43.5 -5.  22. ]\n",
      "[ 6.5  6.5  7.5  1.5 -4.  22. ]\n",
      "[ 5.5  6.5  8.5  1.5 -3.  22. ]\n",
      "[ 4.5  6.5  9.5  1.5 -2.  22. ]\n",
      "[ 3.5  6.5 10.5 43.5 -1.  22. ]\n",
      "[ 2.5  6.5 11.5 11.5  0.  22. ]\n",
      "[ 1.5  6.5 12.5 11.5  1.  22. ]\n",
      "[ 0.5  6.5 13.5 11.5  2.  22. ]\n",
      "[ 2.5  2.5  0.5  8.5  3.  22. ]\n",
      "[ 1.5  2.5  1.5  8.5  4.  22. ]\n",
      "[ 0.5  2.5  2.5  8.5  5.  22. ]\n",
      "[ 4.5  6.5  0.5 22.5  6.  22. ]\n",
      "[ 3.5  6.5  1.5 22.5  7.  22. ]\n",
      "[ 2.5  6.5  2.5 22.5  8.  22. ]\n",
      "[ 1.5  6.5  3.5 12.5  9.  22. ]\n",
      "[ 0.5  6.5  4.5 12.5 10.  22. ]\n",
      "[ 6.5  2.5  0.5  0.5 11.  22. ]\n",
      "[ 5.5  2.5  1.5  0.5 12.  22. ]\n",
      "[ 4.5  2.5  2.5  0.5 13.  22. ]\n",
      "[ 3.5  2.5  3.5  0.5 14.  22. ]\n",
      "[ 2.5  2.5  4.5  0.5 15.  22. ]\n",
      "[ 1.5  2.5  5.5  0.5 16.  22. ]\n",
      "[ 0.5  2.5  6.5  0.5 17.  22. ]\n",
      "[ 7.5  6.5  0.5 12.5 18.  22. ]\n",
      "[ 6.5  6.5  1.5 12.5 19.  22. ]\n",
      "[ 5.5  6.5  2.5 12.5 20.  22. ]\n",
      "[ 4.5  6.5  3.5 24.5 21.  22. ]\n",
      "[ 3.5  6.5  4.5 24.5 22.  22. ]\n",
      "[ 2.5  6.5  5.5 24.5 23.  22. ]\n",
      "[ 1.5  6.5  6.5 24.5 24.  22. ]\n",
      "[ 5.5  6.5 25.5  1.5 24.  23. ]\n",
      "[ 5.5 25.5  2.5  5.5 23.  23. ]\n",
      "[ 4.5 25.5  3.5  5.5 22.  23. ]\n",
      "[ 3.5 25.5  4.5  5.5 21.  23. ]\n",
      "[ 2.5 13.5  5.5  5.5 20.  23. ]\n",
      "[ 1.5 13.5  6.5  5.5 19.  23. ]\n",
      "[ 0.5 13.5  7.5  5.5 18.  23. ]\n",
      "[ 6.5  1.5  0.5  1.5 17.  23. ]\n",
      "[ 5.5  1.5  1.5  1.5 16.  23. ]\n",
      "[ 4.5  1.5  2.5  1.5 15.  23. ]\n",
      "[ 3.5  1.5  3.5  1.5 14.  23. ]\n",
      "[ 2.5  1.5  4.5  1.5 13.  23. ]\n",
      "[ 1.5  1.5  5.5  1.5 12.  23. ]\n",
      "[ 0.5  1.5  6.5  1.5 11.  23. ]\n",
      "[ 4.5 13.5  0.5  5.5 10.  23. ]\n",
      "[ 3.5 13.5  1.5  5.5  9.  23. ]\n",
      "[ 4.5  3.5 14.5  1.5  9.  24. ]\n",
      "[ 0.5  4.5  4.5 14.5 10.  24. ]\n",
      "[ 6.5  0.5  0.5  2.5 11.  24. ]\n",
      "[ 5.5  0.5  1.5  2.5 12.  24. ]\n",
      "[ 4.5  0.5  2.5  2.5 13.  24. ]\n",
      "[ 3.5  0.5  3.5  2.5 14.  24. ]\n",
      "[ 2.5  0.5  4.5  2.5 15.  24. ]\n",
      "[ 1.5  0.5  5.5  2.5 16.  24. ]\n",
      "[ 0.5  0.5  6.5  2.5 17.  24. ]\n",
      "[ 7.5  4.5  0.5 14.5 18.  24. ]\n",
      "[ 6.5  4.5  1.5 14.5 19.  24. ]\n",
      "[ 5.5  4.5  2.5 14.5 20.  24. ]\n",
      "[ 4.5  4.5  3.5 26.5 21.  24. ]\n",
      "[ 3.5  4.5  4.5 26.5 22.  24. ]\n",
      "[ 2.5  4.5  5.5 26.5 23.  24. ]\n",
      "[ 1.5  4.5  6.5 26.5 24.  24. ]\n",
      "[ 3.5 35.5 27.5  1.5 24.  25. ]\n",
      "[34.5 27.5  2.5  3.5 23.  25. ]\n",
      "[ 2.5 47.5 28.5  2.5 23.  26. ]\n",
      "[46.5 28.5  3.5  2.5 22.  26. ]\n",
      "[ 1.5 46.5 29.5  3.5 22.  27. ]\n",
      "[45.5 29.5  4.5  1.5 21.  27. ]\n",
      "[44.5 17.5  5.5  1.5 20.  27. ]\n",
      "[43.5 17.5  6.5  1.5 19.  27. ]\n",
      "[42.5 17.5  7.5  1.5 18.  27. ]\n",
      "[41.5  2.5  8.5  1.5 17.  27. ]\n",
      "[40.5  2.5  9.5  1.5 16.  27. ]\n",
      "[ 1.5  9.5  2.5 40.5 16.  26. ]\n",
      "[ 8.5  2.5 41.5  1.5 17.  26. ]\n",
      "[ 7.5  2.5 42.5 16.5 18.  26. ]\n",
      "[ 6.5  2.5 43.5 16.5 19.  26. ]\n",
      "[ 5.5  2.5 44.5 16.5 20.  26. ]\n",
      "[ 4.5  2.5 45.5 28.5 21.  26. ]\n",
      "[27.5  4.5  3.5 32.5 21.  25. ]\n",
      "[ 3.5  3.5 33.5 27.5 22.  25. ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of steps taken in pred Path 95\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of steps taken in A* Path,  44\n",
      "[22.5 16.5  2.5  9.5 -7.  36. ]\n",
      "[ 1.5  9.5 23.5 16.5 -6.  36. ]\n",
      "[ 0.5  9.5 24.5  4.5 -5.  36. ]\n",
      "[11.5  6.5  0.5  1.5 -4.  36. ]\n",
      "[10.5  6.5  1.5  1.5 -3.  36. ]\n",
      "[ 9.5  6.5  2.5  1.5 -2.  36. ]\n",
      "[ 8.5  6.5  3.5  1.5 -1.  36. ]\n",
      "[ 7.5  6.5  4.5  1.5  0.  36. ]\n",
      "[ 6.5  6.5  5.5  1.5  1.  36. ]\n",
      "[ 5.5  6.5  6.5  1.5  2.  36. ]\n",
      "[ 4.5  6.5  7.5  1.5  3.  36. ]\n",
      "[ 3.5  6.5  8.5  1.5  4.  36. ]\n",
      "[ 2.5  6.5  9.5  1.5  5.  36. ]\n",
      "[ 1.5  6.5 10.5  1.5  6.  36. ]\n",
      "[ 0.5  6.5 11.5  1.5  7.  36. ]\n",
      "[ 5.5 11.5  2.5  0.5  7.  37. ]\n",
      "[ 4.5 11.5  3.5  0.5  7.  38. ]\n",
      "[ 3.5 11.5  4.5  0.5  7.  39. ]\n",
      "[ 2.5 11.5  5.5  0.5  7.  40. ]\n",
      "[ 1.5 11.5  6.5  0.5  7.  41. ]\n",
      "[ 0.5 11.5  7.5  0.5  7.  42. ]\n",
      "[ 2.5 48.5  0.5  1.5  7.  43. ]\n",
      "[ 1.5 48.5  1.5  1.5  7.  44. ]\n",
      "[47.5  1.5  2.5  1.5  6.  44. ]\n",
      "[ 0.5  2.5  2.5 47.5  6.  43. ]\n",
      "[ 7.5  1.5  0.5 10.5  6.  42. ]\n",
      "[ 9.5  7.5  2.5  0.5  5.  42. ]\n",
      "[ 2.5 46.5  0.5  3.5  5.  43. ]\n",
      "[ 1.5 46.5  1.5  3.5  5.  44. ]\n",
      "[45.5  1.5  4.5  1.5  4.  44. ]\n",
      "[ 0.5  4.5  2.5 45.5  4.  43. ]\n",
      "[ 7.5  3.5  0.5  8.5  4.  42. ]\n",
      "[ 7.5  7.5  4.5  0.5  3.  42. ]\n",
      "[ 2.5 44.5  0.5  5.5  3.  43. ]\n",
      "[ 1.5 44.5  1.5  5.5  3.  44. ]\n",
      "[43.5  1.5  6.5  1.5  2.  44. ]\n",
      "[ 0.5  6.5  2.5 43.5  2.  43. ]\n",
      "[ 7.5  5.5  0.5  6.5  2.  42. ]\n",
      "[ 5.5  7.5  6.5  0.5  1.  42. ]\n",
      "[ 2.5 42.5  0.5  7.5  1.  43. ]\n",
      "[ 1.5 42.5  1.5  7.5  1.  44. ]\n",
      "[41.5  1.5  8.5  1.5  0.  44. ]\n",
      "[ 0.5  8.5  2.5 41.5  0.  43. ]\n",
      "[ 7.5  7.5  0.5  4.5  0.  42. ]\n",
      "[ 3.5  7.5  8.5  0.5 -1.  42. ]\n",
      "[ 2.5 40.5  0.5  9.5 -1.  43. ]\n",
      "[ 1.5 40.5  1.5  9.5 -1.  44. ]\n",
      "[39.5  1.5 10.5  1.5 -2.  44. ]\n",
      "[ 0.5 10.5  2.5 39.5 -2.  43. ]\n",
      "[ 7.5  9.5  0.5  2.5 -2.  42. ]\n",
      "[ 1.5  7.5 10.5  0.5 -3.  42. ]\n",
      "[ 2.5 38.5  0.5 11.5 -3.  43. ]\n",
      "[ 1.5 38.5  1.5 11.5 -3.  44. ]\n",
      "[37.5  1.5 12.5  1.5 -4.  44. ]\n",
      "[ 0.5 12.5  2.5 37.5 -4.  43. ]\n",
      "[ 7.5 11.5  0.5  0.5 -4.  42. ]\n",
      "[36.5 10.5  0.5  3.5 -5.  42. ]\n",
      "[ 9.5  0.5  4.5 24.5 -5.  41. ]\n",
      "[11.5  1.5  0.5  6.5 -4.  41. ]\n",
      "[10.5  1.5  1.5  6.5 -3.  41. ]\n",
      "[ 9.5  1.5  2.5  6.5 -2.  41. ]\n",
      "[ 8.5  1.5  3.5  6.5 -1.  41. ]\n",
      "[ 7.5  1.5  4.5  6.5  0.  41. ]\n",
      "[ 6.5  1.5  5.5  6.5  1.  41. ]\n",
      "[ 5.5  1.5  6.5  6.5  2.  41. ]\n",
      "[ 4.5  1.5  7.5  6.5  3.  41. ]\n",
      "[ 3.5  1.5  8.5  6.5  4.  41. ]\n",
      "[ 2.5  1.5  9.5  6.5  5.  41. ]\n",
      "[ 1.5  1.5 10.5  6.5  6.  41. ]\n",
      "[ 5.5  1.5  2.5 10.5  6.  40. ]\n",
      "[ 9.5  5.5  2.5  2.5  5.  40. ]\n",
      "[ 8.5  5.5  3.5  2.5  4.  40. ]\n",
      "[ 7.5  5.5  4.5  2.5  3.  40. ]\n",
      "[ 6.5  5.5  5.5  2.5  2.  40. ]\n",
      "[ 5.5  5.5  6.5  2.5  1.  40. ]\n",
      "[ 4.5  5.5  7.5  2.5  0.  40. ]\n",
      "[ 3.5  5.5  8.5  2.5 -1.  40. ]\n",
      "[ 2.5  5.5  9.5  2.5 -2.  40. ]\n",
      "[ 1.5  5.5 10.5  2.5 -3.  40. ]\n",
      "[ 0.5  5.5 11.5  2.5 -4.  40. ]\n",
      "[24.5  8.5  0.5  5.5 -5.  40. ]\n",
      "[23.5 20.5  1.5  5.5 -6.  40. ]\n",
      "[22.5 20.5  2.5  5.5 -7.  40. ]\n",
      "[21.5 20.5  3.5  5.5 -8.  40. ]\n",
      "[20.5 20.5  4.5  5.5 -9.  40. ]\n",
      "[ 19.5  20.5   5.5   5.5 -10.   40. ]\n",
      "[ 18.5  20.5   6.5   5.5 -11.   40. ]\n",
      "[ 17.5  44.5   7.5   5.5 -12.   40. ]\n",
      "[ 16.5  44.5   8.5   5.5 -13.   40. ]\n",
      "[ 15.5   7.5   9.5   5.5 -14.   40. ]\n",
      "[ 14.5   7.5  10.5   5.5 -15.   40. ]\n",
      "[ 13.5   7.5  11.5   5.5 -16.   40. ]\n",
      "[  4.5  13.5   8.5  11.5 -16.   41. ]\n",
      "[ 10.5   4.5  14.5   8.5 -15.   41. ]\n",
      "[  9.5   4.5  15.5   8.5 -14.   41. ]\n",
      "[  8.5   4.5  16.5  45.5 -13.   41. ]\n",
      "[  7.5   4.5  17.5  45.5 -12.   41. ]\n",
      "[  6.5   4.5  18.5  21.5 -11.   41. ]\n",
      "[  5.5   4.5  19.5  21.5 -10.   41. ]\n",
      "[ 4.5  4.5 20.5 21.5 -9.  41. ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of steps taken in pred Path 101\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "pred_len = []\n",
    "astar_len = []\n",
    "n_test = 0\n",
    "while n_test < 2:\n",
    "    # TODO: Generalize to any map shape\n",
    "    start = (random.randint(1,49), random.randint(1,49))\n",
    "    goal = (random.randint(1,49), random.randint(1,49))\n",
    "    arr, test_MAP = placeRandomRooms(map_size, minRoomSize=3, maxRoomSize=15, roomStep = 1, margin = 1, attempts = 100)\n",
    "    # If path is available, get test info\n",
    "    try:\n",
    "        pred_path = test_on_new_map(test_MAP, arr, start, goal, clf)\n",
    "        OccupancyGridMap(arr, 1).plot()\n",
    "        plot_path(pred_path)\n",
    "        pred_len.append(len(pred_path))\n",
    "        print('Number of steps taken in pred Path', len(pred_path))\n",
    "        astar_len.append(len(get_path(start, goal, arr, False)))\n",
    "        n_test += 1\n",
    "    except:\n",
    "        # No path found\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[41.0, 0.0, 9.0, 0.0]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls,_ = synthetic_sensor(train_MAP2, (9,40), direction=(0,0))\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_path_with_lines(pred_path, MAP):\n",
    "    '''\n",
    "    Given predicted path nodes and map, \n",
    "    plot the path and the sensor readings for each node\n",
    "    '''\n",
    "    # Update node positions for shapely plotting\n",
    "    pred_path = [(p[0]+0.5, p[1]+0.5) for p in pred_path]\n",
    "    # Save filenames for GIF creation\n",
    "    filenames=[]\n",
    "    for i, node in enumerate(pred_path):\n",
    "        # Create fig\n",
    "        fig = plt.figure(frameon=False)\n",
    "        fig.set_size_inches(6,6)\n",
    "        plt.plot(*LineString(pred_path).xy)\n",
    "        plt.scatter(*node, s=30, alpha=1.0)\n",
    "        # Get lines from sensor \n",
    "        _, lines = synthetic_sensor(MAP, node)\n",
    "        for index, l in enumerate(MAP): \n",
    "            if index != 0:\n",
    "                plt.fill(*l.xy, alpha=1)\n",
    "            else:\n",
    "                plt.plot(*l.xy, alpha=1)\n",
    "        for k, line in enumerate(lines):\n",
    "            plt.plot(*line.xy, alpha=0.25)\n",
    "        filenames.append('img_{}.png'.format(i))\n",
    "        plt.savefig('img_{}.png'.format(i))\n",
    "        plt.close()\n",
    "    \n",
    "    # Make GIF\n",
    "    images = []\n",
    "    for filename in filenames:\n",
    "        images.append(imageio.imread(filename))\n",
    "    imageio.mimsave('demo.gif', images)\n",
    "        \n",
    "plot_path_with_lines(pred_path, test_MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-244-4d33aa6676c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotebook\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "# DL Solution ... not currently learning. \n",
    "\n",
    "import torch\n",
    "class SensorData(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df.copy()\n",
    "        self.mms = MinMaxScaler()\n",
    "        self.mms.fit(df.drop('out', axis=1).values)\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.df.iloc[idx]\n",
    "        x = self.mms.transform(sample.drop('out').values.astype(np.float32).reshape(1,-1))\n",
    "        y = sample['out']\n",
    "        return (torch.from_numpy(x).double(), y)\n",
    "    \n",
    "ds = SensorData(df)\n",
    "train_loader = torch.utils.data.DataLoader(ds,64,True, num_workers=0, pin_memory=True)\n",
    "\n",
    "from resnet1d import ResNet1D\n",
    "model = ResNet1D(1,64,3,3,1,24,4).cuda()\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "\n",
    "loss = 0\n",
    "for i in range(20):\n",
    "    ep_loss = 0\n",
    "    for batch in tqdm(train_loader):\n",
    "        model.train()\n",
    "        x,y = batch[0].cuda().float(), batch[1].cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out = model(x)\n",
    "        loss = criterion(out,y.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        ep_loss += loss.item()\n",
    "        \n",
    "    print(ep_loss/len(train_loader))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
